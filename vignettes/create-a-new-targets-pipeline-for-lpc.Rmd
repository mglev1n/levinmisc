---
title: "Create a New Targets Pipeline for LPC"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{create-a-new-targets-pipeline-for-lpc}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r setup}
library(levinmisc)
```

<!-- WARNING - This vignette is generated by {fusen} from /dev/LPC_targets_project.Rmd: do not edit by hand -->

<!-- 
Run this 'development' chunk

Store every call to library() that you need to run chunks line by line, as in a classical Rmd for analysis
-->


<!--

# Description of your package

This will fill the description of your package.
Fill and run the content of this chunk, before anything else. 

Note: when you will use other flat templates, this part will be in a separate file. Do not be surprised!
--> 


## Introduction

The `targets` package is a tool for developing reproducible research workflows in R. Details of the package motivation and tools are described in detail: https://books.ropensci.org/targets/ and https://docs.ropensci.org/targets/.


### Example Workflow

1. Create a new R project

1. Run the `levinmisc::populate_targets_proj()` function in the R console - this function is described below in detail, and will initialize your project with helpful files/folders to start building your `targets` pipeline.

1. Modify the `Pipelines.qmd` file to specify your analyses. The `targets` documentation can be useful for specifics.

1. Knit/Render `Pipelines.qmd` to convert your markdown document into a series of R scripts that will actually run your analyses.

1. Run `submit-targets.sh` from a terminal window to submit your `targets` pipeline to the LPC for execution. Details of possible command line arguments to this script are described below.

1. Modify `Results.qmd` to present the results of your analyses. Rendering this file allows you to mix text describing your analyses/methods and include citations alongside the actual results of your pipeline. The `targets::tar_read()` function should be used heavily to load pre-computed results from your pipeline.


## populate_targets_proj()

The `populate_targets_proj` function can be run within a new project folder to initialize the project with the files/folders necessary for deploying a `targets` pipeline on the LPC at Penn. This includes creating LSF templates, a `Pipelines.qmd` file containing boilerplate for running analyses, and a `Results.qmd` file which can be used to visualize the results.


<!--
Here is an example on how to use the function.
This should be a reproducible and working example
-->


```{r examples-populate_targets_proj}
#' \dontrun{
#' populate_targets_proj("test")
#' }
```

The `populate_targets_proj()` function creates several files/folders within the project directory. `.make-targets.sh` and `.clustermq_lsf.tmpl` are hidden helper files which are not designed for user interaction, but necessary for submission of jobs to the LSF scheduler. The other files are designed to be edited/used by the user:

  - `Pipeline.qmd` - Quarto markdown file which can be used to create a Target Markdown document that specifies a `targets` pipeline for your analyses. See: https://books.ropensci.org/targets/literate-programming.html#target-markdown for details. Remember to knit/render this document in order to generate the pipeline.
  
  - `Results.qmd` - Quarto markdown file which can be used to display the results generated by the `targets` pipeline specified in `Pipeline.qmd`
  
  - `build_logs/` - Directory where jobs logs are stored
  
  - `submit-targets.sh`- This is a bash script which can be used to run your `targets` pipeline, once `Pipeline.qmd` has been knit/rendered. This script can be run directly from the submission host. This script can accept command line options, which can be useful for parallelizing your pipeline over multiple workers/CPUs:
  
  
```
Usage: ./submit-targets.sh [-n NUM_WORKERS] [-j JOB_NAME] [-o OUTPUT_LOG] [-e ERROR_LOG] [-q QUEUE] [-m MEMORY] [-s SLACK] [-h HELP]

Submit a job using the LSF scheduler with the specified number of CPUs and memory usage.

Options:
  -n NUM_WORKERS Number of workers (cpu cores) to request for running the targets pipeline (default: 1)
  -j JOB_NAME    Name of the job (default: make_targets)
  -o OUTPUT_LOG  Path to the output log file (default: build_logs/targets_%J.out)
  -e ERROR_LOG   Path to the error log file (default: build_logs/targets_%J.err)
  -q QUEUE       Name of the queue to submit the job to (default: voltron_normal)
  -m MEMORY      Memory usage for the job in megabytes (default: 16000)
  -s SLACK       Enable slack notifications; requires setup using slackr::slack_setup() (default: false)
  -h HELP        Display this help message and exit
```


### Slack Notifications

Slack can be used to automatically notify the user of pipeline start/finish using the `-s true` command line flag:

```
./submit-targets.sh -s true
```

Slack notifications are provided using the `slackr` package. The package must be configured separately before Slack notifications are enabled. See https://mrkaye97.github.io/slackr/index.html for more information about `slackr` setup and generation of an Slack API token.


<!--
Here are some unit tests to verify the function works as expected.
-->


<!-- 

# Inflate your package

You're one inflate from paper to box.
Build your package from this very Rmd using `fusen::inflate()` 
-->



<!-- 
- Verify your `"DESCRIPTION"` file has been updated
- Verify your function is in `"R/"` directory
- Verify your test is in `"tests/testthat/"` directory
- Verify this Rmd appears in `"vignettes/"` directory 
-->

