---
title: "flat_genomics_functions.Rmd empty"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r development, include=FALSE}
library(testthat)
```

```{r development-load}
# Load already included functions if relevant
pkgload::load_all(export_all = FALSE)
```

# Plotting

These convenience functions are useful for creating plots from GWAS summary statistics.

## Manhattan plots

The `gg_manhattan_df` function is used to create Manhattan plots. This function can optionally annotated the plot with additional information (eg. gene name, rsid) by using the `annotation_df` amd `label_col` arguments.
    
```{r function-gg_manhattan_df}
#' Create a Manhattan Plot
#'
#' This function is a wrapper around `ggfastman::fast_manhattan` which allows for the creation of a Manhattan plot from a dataframe containing GWAS summary statistics.
#'
#' @param sumstats_df Dataframe containing GWAS summary statistics
#' @param chr_col Name of chromosome column
#' @param pos_col Name of position column
#' @param pval_col Name of p-value column
#' @param annotation_df Optional dataframe containing chromosome, position, and annotation labels
#' @param label_col Name of column in `annotation_df` containing annotations to include on the plot
#' @param build (string) One of "hg18", "hg19", or "hg38" (passed to `ggfastman`)
#' @param color1 (string) Color for odd-numbered chromosomes (passed to `ggfastman`)
#' @param color2 (string) Color for even-numbered chromosomes (passed to `ggfastman`)
#' @param speed (string) One of "slow", "fast", or "ultrafast"; passed to `ggfastman` to control plotting speed
#' @param ... Arguments passed to `ggfastman::fast_manhattan`
#'
#' @return A ggplot2 object
#' @export
#' @import dplyr ggplot2
#' @concept genomics
#' @family {plotting}

gg_manhattan_df <- function(sumstats_df, annotation_df = NULL, chr_col = chromosome, pos_col = position, pval_col = p_value, label_col = gene, build = "hg19", color1 = "#045ea7", color2 = "#82afd3", speed = "slow", ...) {
  if (!is.null((annotation_df))) {
    df <- sumstats_df %>%
      select(chr = {{ chr_col }}, pos = {{ pos_col }}, pvalue = {{ pval_col }}) %>%
      filter(pvalue < 0.001) %>%
      collect() %>%
      as_tibble() %>%
      mutate(across(.cols = everything(), as.numeric)) %>%
      tidyr::drop_na() %>%
      left_join(annotation_df %>% select(chr = {{ chr_col }}, pos = {{ pos_col }}, label = {{ label_col }})) %>%
      mutate(highlight = case_when(
        pvalue < 5e-8 ~ "#990000",
        TRUE ~ NA_character_
      ))
  } else {
    df <- sumstats_df %>%
      select(chr = {{ chr_col }}, pos = {{ pos_col }}, pvalue = {{ pval_col }}) %>%
      filter(pvalue < 0.001) %>%
      collect() %>%
      as_tibble() %>%
      mutate(across(.cols = everything(), as.numeric)) %>%
      tidyr::drop_na() %>%
      mutate(highlight = case_when(
        pvalue < 5e-8 ~ "#990000",
        TRUE ~ NA_character_
      ))
  }

  cli::cli_alert_info("Creating Manhattan Plot")
  if (!is.null((annotation_df))) {
    max_log10_p <- -log10(min(df$pvalue))

    plot <- df %>%
      ggfastman::fast_manhattan(
        build = build,
        color1 = color1,
        color2 = color2,
        pointsize = pointsize,
        speed = speed,
        ...
      ) +
      geom_hline(yintercept = -log10(5e-8), linetype = "dotted") +
      ggrepel::geom_text_repel(
        data = . %>%
          filter(!is.na(label)),
        aes(label = label),
        color = "black",
        force_pull = 0, # do not pull toward data points
        nudge_y = 10,
        direction = "x",
        angle = 90,
        hjust = 0,
        segment.size = 0.2,
        segment.curvature = -1e-20,
        segment.angle = 175,
        ylim = c(max_log10_p + 10, NA),
        max.overlaps = 50
      )
  } else {
    plot <- df %>%
      ggfastman::fast_manhattan(
        build = build,
        color1 = color1,
        color2 = color2,
        pointsize = pointsize,
        speed = speed,
        ...
      ) +
      geom_hline(yintercept = -log10(5e-8), linetype = "dotted")
  }

  plot <- plot +
    ggplot2::scale_y_continuous(expand = expansion(mult = c(0.01, 0.30)), name = "-log<sub>10</sub>(p-value)") +
    theme_bw(base_size = 16) +
    theme(
      panel.grid = element_blank(),
      axis.title.y = ggtext::element_markdown()
    )

  return(plot)
}
```
  
```{r example-gg_manhattan_df}
#' \dontrun{
#' gg_manhattan_df(sumstats_df)
#' }
```
  
```{r tests-gg_manhattan_df}
test_that("gg_manhattan_df works", {
  expect_true(inherits(gg_manhattan_df, "function"))
})

test_that("gg_manhattan_df returns a ggplot object", {
  locus_df <- tibble(position = sample.int(1000, 100)) %>%
    tidyr::crossing(chromosome = 1:22) %>%
    rowwise() %>%
    mutate(p_value = runif(1, min = 1/1e5, max = 0.99)) %>%
    mutate(label = "Test")

  plot_res <- locus_df %>%
    gg_manhattan_df(chr_col = chromosome, pos_col = position, pval_col = p_value)
  expect_s3_class(plot_res, "ggplot")

  plot_res <- locus_df %>%
    gg_manhattan_df(chr_col = chromosome, pos_col = position, pval_col = p_value, annotation_df = locus_df, label_col = label)
  expect_s3_class(plot_res, "ggplot")
})
```

  
## QQ plots

The `gg_qq_df` function can be used to generate a qq plot to visually evaluate for test statistic inflation, and calculate lambda GC to quantify any inflation.
    
```{r function-gg_qq_df}
#' Create a QQ plot
#'
#' This function is a wrapper around `ggfastman::fast_qq` which allows for the creation of a QQ plot from a dataframe containing GWAS summary statistics.
#'
#' @param sumstats_df Dataframe containing GWAS summary statistics
#' @param pval_col Name of p-value column
#' @param ... Arguments passed to `ggfastman::fast_qq`
#'
#' @return A ggplot2 object
#'
#' @export
#' @import dplyr ggplot2
#' @concept genomics
#' @family {plotting}

gg_qq_df <- function(sumstats_df, pval_col = p_value, ...) {
  df <- sumstats_df %>%
    select(pvalue = {{ pval_col }}) %>%
    collect() %>%
    as_tibble() %>%
    mutate(across(.cols = everything(), as.numeric)) %>%
    pull(pvalue)

  cli::cli_alert_info("Creating QQ Plot")
  plot <- df %>%
    ggfastman::fast_qq(...)

  return(plot)
}
```
  
```{r example-gg_qq_df}
#' \dontrun{
#' gg_qq_df(sumstats_df)
#' }
```
  
```{r tests-gg_qq_df}
test_that("gg_qq_df works", {
  expect_true(inherits(gg_qq_df, "function"))
})

test_that("gg_qq_df returns a ggplot object", {
  plot_res <- tibble(pval = runif(1000)) %>%
    gg_qq_df(pval_col = pval)
  expect_s3_class(plot_res, "ggplot")
})
```
  
---

# Annotation

These convenience functions are useful for adding additional information to GWAS summary stastics.

## Add rsids

This function can be used rapidly add rsids to GWAS summary statistics by chromosome:position.
    
```{r function-annotate_rsids}
#' Annotate a dataframe containing genomic coordinates with rsids
#' 
#' This function can be used rapidly add rsids to GWAS summary statistics or any other dataframe containing genomic coordinates (eg. chromosome and position). This is a rapid function that does not explicitly account for differences in variants at each position, strand flips, etc.)
#' 
#' @param df Dataframe containing genomic coordinates to annotate with rsid
#' @param dbSNP Bioconductor object containing SNP locations and alleles to be used for annotation (default: `SNPlocs.Hsapiens.dbSNP144.GRCh37::SNPlocs.Hsapiens.dbSNP144.GRCh37`)
#' @param chrom_col Chromosome column 
#' @param pos_col Position column
#'
#' @return A dataframe containing the original contents, with an additional `rsid` column.
#' 
#' @export
#' @concept genomics 
#' @family {annotation}

annotate_rsids <- function(df, dbSNP = SNPlocs.Hsapiens.dbSNP144.GRCh37::SNPlocs.Hsapiens.dbSNP144.GRCh37, chrom_col = Chromosome, pos_col = Position) {
  if (sum(stringr::str_detect(names(df), "rsid")) > 0) {
    cli::cli_abort("A column named 'rsid' is already present")
  }

  df <- df %>%
    dplyr::rename(chrom = {{ chrom_col }}) %>%
    dplyr::mutate(chrom = as.character(chrom)) %>%
    # mutate(chrom = glue::glue("{chrom}")) %>%
    dplyr::rename(start = {{ pos_col }}) %>%
    dplyr::mutate(end = start)

  # return(df)

  df_annotated <- df %>%
    dplyr::group_split(chrom) %>%
    purrr::map_dfr(function(df) {
      chrom <- df$chrom[1]

      cli::cli_alert_info("Annotating chromosome {chrom}")

      df_granges <- df %>%
        GenomicRanges::makeGRangesFromDataFrame(keep.extra.columns = TRUE, starts.in.df.are.0based = FALSE)

      snps_granges <- BSgenome::snpsByOverlaps(dbSNP, df_granges) %>%
        unique()

      plyranges::join_overlap_left_directed(df_granges, snps_granges) %>%
        as.data.frame() %>%
        mutate(seqnames = as.character(seqnames))
    })

  df_annotated %>%
    dplyr::rename(
      {{ chrom_col }} := seqnames,
      {{ pos_col }} := start
    ) %>%
    # dplyr::mutate({{ chr_col }} := as.numeric({{ chr_col }})) %>%
    # dplyr::mutate({{ pos_col }} := as.numeric({{ pos_col }})) %>%
    dplyr::rename(rsid = RefSNP_id) %>%
    dplyr::select(-end, -width, -strand, -alleles_as_ambig) %>%
    dplyr::select(rsid, everything()) %>%
    readr::type_convert(col_types = readr::cols())
}
```
  
```{r example-annotate_rsids}
#' \dontrun{
#' annotate_rsids(sumstats_df)
#' }
```
  
```{r tests-annotate_rsids}
test_that("annotate_rsids works", {
  expect_true(inherits(annotate_rsids, "function")) 
})

test_that("annotate_rsids returns a tibble", {
  df <- tibble(Chromosome = 1) %>%
    tidyr::crossing(Position = 1e4:1e5)
  rsids_res <- annotate_rsids(df)
  expect_s3_class(rsids_res, "data.frame")
})
```
  
---

# GWAS Meta-analysis

GWAS summary statistics from multiple studies can be combined using meta-analysis. The following functions are useful for orchestrating GWAS meta-analysis using R.

## METAL

METAL (<https://github.com/statgen/METAL>) is a common command-line tool for performing GWAS meta-analysis. The following functions can be used to configure and run METAL directly from R.

## Configure METAL
    
```{r function-metal_config}
#' Create a configuration file for METAL
#' 
#' This function can be used to generate a configuration for METAL, a tool for performing meta-analysis of GWAS summary statistics <https://github.com/statgen/METAL>. The file created by this function can be used to run a meta-analysis. Details of the arguments to METAL are described in the METAL documentation: <https://genome.sph.umich.edu/wiki/METAL_Documentation>.
#' 
#' @param config_name (string) Name of the configuration
#' @param output_dir (path) Path to output directory where GWAS meta-analysis data should be stored
#' @param study_files (list) List of paths to summary statistics that should be included in the GWAS
#' @param SCHEME (string) Either "SAMPLESIZE" or "STDERR" (default), corresponding to the METAL analysis scheme
#' @param AVERAGEFREQ (string) Either "ON" (default) or "OFF", allowing METAL to report the mean effect allele frequency across files
#' @param MINMAXFREQ (string) Either "ON" (default) or "OFF", allowing METAL to report the min/max effect allele frequency across files
#' @param TRACKPOSITIONS (string) Either "ON" (default) or "OFF", allowing METAL to report chromosome/position in the output
#' @param MARKERLABEL (string) Column containing unique markers to analyze (this column must be named the same across all input files)
#' @param CHROMOSOMELABEL (string) Column containing chromosomes (this column must be named the same across all input files)
#' @param POSITIONLABEL (string) Column containing genomic positions (this column must be named the same across all input files)
#' @param EFFECT_ALLELE (string) Column containing effect alleles (this column must be named the same across all input files)
#' @param OTHER_ALLELE (string) Column containing non-effect alleles (this column must be named the same across all input files)
#' @param EFFECTLABEL (string) Column containing effect sizes corresponding to the effect allele (this column must be named the same across all input files)
#' @param STDERR (string) Column containing standard errors fo the effect estimate (this column must be named the same across all input files)
#' @param FREQLABEL (string) Column containing effect allele frequencies (this column must be named the same across all input files)
#' @param NCASE (string) Column containing number of cases (this column must be named the same across all input files)
#' @param NCONTROL (string) Column containing number of controls (this column must be named the same across all input files)
#' @param SAMPLESIZE (string) Column containing total samplesize (this column must be named the same across all input files)
#'
#' @return Path to METAL configuration file
#' @concept genomics
#' @family GWAS meta-analysis
#' @seealso Run GWAS meta-analysis using METAL: [levinmisc::metal_run()]
#' @export

metal_config <- function(config_name, output_dir, study_files, SCHEME = "STDERR", AVERAGEFREQ = "ON", MINMAXFREQ = "OFF", TRACKPOSITIONS = "ON", MARKERLABEL = "MARKER", CHROMOSOMELABEL = "CHROM", POSITIONLABEL = "POS", EFFECT_ALLELE = "EFFECT_ALLELE", OTHER_ALLELE = "OTHER_ALLELE", EFFECTLABEL = "BETA", STDERR = "SE", FREQLABEL = "EAF", NCASE = "N_CASE", NCONTROL = "N_CONTROL", SAMPLESIZE = "N") {
  
  fs::dir_create(output_dir, recurse = TRUE)

  config_outfile <- fs::path(output_dir, paste0(config_name, "_metal-config.txt"))
  meta_outfile <- fs::path(normalizePath(output_dir), config_name)

  study_files <- paste0(glue::glue("PROCESS {normalizePath(study_files)}"), collapse = "\n")

  config_text <- glue::glue(
    "SCHEME {SCHEME}
    AVERAGEFREQ {AVERAGEFREQ}
    MINMAXFREQ {MINMAXFREQ}
    TRACKPOSITIONs {TRACKPOSITIONS}
    MARKERLABEL {MARKERLABEL}
    CHROMOSOMELABEL {CHROMOSOMELABEL}
    POSITIONLABEL {POSITIONLABEL}
    ALLELELABELS {EFFECT_ALLELE} {OTHER_ALLELE}
    EFFECTLABEL {EFFECTLABEL}
    STDERR {STDERR}
    FREQLABEL {FREQLABEL}
    
    CUSTOMVARIABLE NCASE
    LABEL NCASE as {NCASE}
    
    CUSTOMVARIABLE NCONTROL
    LABEL NCONTROL as {NCONTROL}
    
    CUSTOMVARIABLE SAMPLESIZE
    LABEL SAMPLESIZE as {SAMPLESIZE}
    
    {study_files}
    
    OUTFILE {meta_outfile}_metal- .txt
    ANALYZE HETEROGENEITY
    
    QUIT
    "
  )

  readr::write_lines(x = config_text, file = config_outfile)

  return(config_outfile)
}
```
  
```{r example-metal_config}
#' \dontrun{
#' metal_config(config_name = "name-of-analysis", output_dir = "/path/to/output/", study_files = list("/path/to/sumstats_1.txt", "/path/to/sumstats_2.txt))
#' }
```
  
```{r tests-metal_config}
test_that("metal_config works", {
  expect_true(inherits(metal_config, "function")) 
})
```

## Run METAL
    
```{r function-metal_run}
#' Use METAL to run a GWAS meta-analysis
#' 
#' This function is a wrapper for METAL, a tool for performing meta-analysis of GWAS summary statistics <https://github.com/statgen/METAL>. Details of the arguments to METAL are described in the METAL documentation: <https://genome.sph.umich.edu/wiki/METAL_Documentation>.
#' 
#' @param config_file (path) Path to a METAL configuration file (this can be generated using [levinmisc::metal_config()])
#' @param metal_path (path) Path to the METAL binary
#'
#' @return Path to gzip-formatted text file containing meta-analysis summary statistics
#' @concept genomics
#' @family GWAS meta-analysis
#' @seealso Create a METAL configuration file: [levinmisc::metal_config()]
#' @export

metal_run <- function(config_file, metal_path) {
  metal_path <- normalizePath(metal_path)
  config_file <- normalizePath(config_file)

  processx::run(metal_path, args = config_file)
  output_file <- str_replace(config_file, "-config.txt", "-1.txt")

  processx::run("gzip", c("-f", output_file))

  output_file <- str_replace(output_file, ".txt", ".txt.gz")

  return(output_file)
}
```
  
```{r example-metal_run}
#' \dontrun{
#' metal_run(config_file = "config.txt", metal_path = "/path/to/metal_binary")
#' }
```
  
```{r tests-metal_run}
test_that("metal_run works", {
  expect_true(inherits(metal_run, "function")) 
})
```

## Run MR-MEGA
    
```{r function-mr_mega}
#' Perform multi-ancestry GWAS meta-analysis using MR-MEGA
#' 
#' This function is a wrapper around MR-MEGA, which uses meta-regression to combine GWAS summart statistics while accounting for study/population-specific components of genetic variation. The method was described in Magi et al. (Human Molecular Genetics 2017; <https://doi.org/10.1093/hmg/ddx280>), and the package can be obtained from the Estonian Genome Centre (<https://genomics.ut.ee/en/tools>).
#' 
#' @param sumstats_files List of files containing GWAS summary statistics. These files should all contain the same column header.
#' @param mr_mega_bin Path to MR-MEGA binary
#' @param marker_col Column containing unique markers for each variant
#' @param chr_col Column containing the chromosome
#' @param pos_col Column containing the position
#' @param effect_allele_col Column containing the effect allele
#' @param other_allele_col Column containing the non-effect allele
#' @param eaf_col Column containing effect allele frequencies
#' @param beta_col Column containing effect estimates
#' @param se_col Column containing standard errors
#' @param p_value_col Column containing p-value
#' @param samplesize_col Column containing sample size
#' @param n_pcs Number of genetic principal components to include in the meta-regression.
#'
#' @return A data.frame containing the GWAS summary statistics from the meta-regression
#' @concept genomics
#' @family GWAS meta-analysis
#' @export

mr_mega <- function(sumstats_files, mr_mega_bin, marker_col = MARKER, chr_col = CHROM, pos_col = POS, effect_allele_col = EFFECT_ALLELE, other_allele_col = OTHER_ALLELE, eaf_col = EAF, beta_col = BETA, se_col = SE, p_value_col = P, samplesize_col = N, n_pcs = 3) {
  # set shell for calling MR-MEGA
  shell <- ifelse(Sys.info()["sysname"] == "Windows", "cmd", "sh")

  # write sumstats to temporary .txt files and return list of locations
  cli::cli_alert_info("Writing input files")
  mrmega_sumstats <- map(sumstats_files, function(sumstats_file) {
    file <- fs::file_temp()
    study <- basename(sumstats_file)
    sumstats_file %>%
      vroom::vroom() %>%
      select(MARKERNAME = {{ marker_col }}, EA = {{ effect_allele_col }}, NEA = {{ other_allele_col }}, BETA = {{ beta_col }}, SE = {{ se_col }}, EAF = {{ eaf_col }}, N = {{ samplesize_col }}, CHROMOSOME = {{ chr_col }}, POSITION = {{ pos_col }}) %>%
      vroom::vroom_write(file)

    return(fs::path_abs(file))
  })

  # write mrmega.in file with information about temporary files
  cli::cli_alert_info("Writing MR-MEGA script")
  mrmega_infile <- fs::file_temp()
  mrmega_sumstats %>%
    glue::glue_collapse(sep = "\n") %>%
    readr::write_lines(mrmega_infile)

  # run MR-MEGA
  cli::cli_alert_info("Running MR-MEGA")
  mrmega_outfile <- fs::file_temp()

  # pcs <- length(sumstats_files) - 3

  processx::run(mr_mega_bin,
    c("-i", mrmega_infile, "--qt", "--pc", n_pcs, "-o", mrmega_outfile),
    echo_cmd = TRUE,
    echo = TRUE
  )

  # read results
  cli::cli_alert_info("Reading MR-MEGA results")
  mrmega_res <- vroom(paste0(mrmega_outfile, ".result")) %>%
    janitor::clean_names()

  return(mrmega_res)
}
```
  
```{r example-mr_mega}
#' \dontrun{
#' mr_mega(sumstats_files = list("/path/to/sumstats_1.txt.gz", "/path/to/sumstats_2.txt.gz), mr_mega_bin = "/path/to/MR-MEGA")
#' }
```
  
```{r tests-mr_mega}
test_that("mr_mega works", {
  expect_true(inherits(mr_mega, "function")) 
})
```
  

---  
  
# Colocalization

Colocalization is a technique for evaluating the evidence supporting the presence of shared causal variant(s) at a given locus across two or more traits. Several methods of colocalization have been described, which generally leverage GWAS summary statistics across multiple traits. The methods use either proportional or enumeration approaches, which make different assumptions and test different hypotheses.

## HyPrColoc

This function is a convenience wrapper around [hyprcoloc::hyprcoloc()] that takes a dataframe as input, and performs mutli-trait colocalization using HyPrColoc, a Bayesian enumeration colocalization method which makes the assumption of a single causal variant at the locus. Details of the HyPrColoc method are described in Foley et al. (Nature Communications 2021; <https://doi.org/10.1038/s41467-020-20885-8>).

```{r function-hyprcoloc_df}
#' Run multi-trait colocalization using HyPrColoc
#' 
#' This function is a convenience wrapper around [hyprcoloc::hyprcoloc()] that takes a dataframe as input, and performs mutli-trait colocalization. Details of the HyPrColoc method are described in Foley et al. (Nature Communications 2021): <https://doi.org/10.1038/s41467-020-20885-8>.
#' 
#' @param df Dataframe containing summary statistics at a single locus, in a "long" format, with one row per variant per trait.
#' @param trait_col Column containing trait names
#' @param snp_col Column containing variant names (eg. rsid, marker_name), which should be consistent across studies
#' @param beta_col Column containing effect estimates from GWAS
#' @param se_col Column containing standard errors of the effect estimates
#' @param type_col Column containing the "type" of trait - this column should contain `1` for binary traits, and `0` for all others
#' @param ... Arguments passed to [hyprcoloc::hyprcoloc()]
#'
#' @return A list containing a data.frame of HyPrColoc results: each row is a cluster of colocalized traits or is coded NA (if no colocalization is identified)
#' @import hyprcoloc tidyr
#' @importFrom purrr possibly
#' @concept genomics
#' @family {colocalization}
#' @export

hyprcoloc_df <- function(df, trait_col = trait, snp_col = rsid, beta_col = beta, se_col = se, type_col = type, ...) {
  df <- df %>%
    select(trait = {{ trait_col }}, rsid = {{ snp_col }}, beta.exposure = {{ beta_col }}, se.exposure = {{ se_col }}, type = {{ type_col }}) %>%
    distinct(rsid, trait, .keep_all = TRUE) %>%
    tidyr::drop_na()

  # return(df)

  .betas <- df %>%
    select(rsid, beta.exposure, trait) %>%
    distinct(rsid, trait, .keep_all = TRUE) %>%
    pivot_wider(names_from = trait, values_from = beta.exposure) %>%
    tibble::column_to_rownames(var = "rsid") %>%
    tidyr::drop_na() %>%
    as.matrix()

  .ses <- df %>%
    select(rsid, se.exposure, trait) %>%
    distinct(rsid, trait, .keep_all = TRUE) %>%
    pivot_wider(names_from = trait, values_from = se.exposure) %>%
    tibble::column_to_rownames(var = "rsid") %>%
    tidyr::drop_na() %>%
    as.matrix()

  .ids <- rownames(.betas)

  .trait_names <- colnames(.betas)

  .binary <- df %>%
    select(trait, type) %>%
    unique() %>%
    pivot_wider(names_from = trait, values_from = type) %>%
    tidyr::drop_na() %>%
    as.matrix()

  .possibly_hyprcoloc <- possibly(hyprcoloc::hyprcoloc)
  # .safely_hyprcoloc <- purrr::safely(hyprcoloc::hyprcoloc)

  .result <- .possibly_hyprcoloc(.betas, .ses, trait.names = .trait_names, snp.id = .ids, binary.outcomes = .binary, ...)

  return(.result)

  # .result <- hyprcoloc(.betas, .ses, trait.names = .trait_names, snp.id = .ids, binary.outcomes = .binary, snpscores = TRUE, uniform.priors = FALSE)

  # .credible_set <- cred_sets(.result, value = 0.95)

  # return(list(.result, .credible_set))

  # hyprcoloc::cred.sets()
}
```
  
```{r example-hyprcoloc_df}
#' \dontrun{
#' hyprcoloc_df(gwas_results_df)
#' }
```
  
```{r tests-hyprcoloc_df}
test_that("hyprcoloc_df works", {
  expect_true(inherits(hyprcoloc_df, "function")) 
  
  df <- tibble::tibble(rsid = letters,
                       beta = runif(26, min = -1, max = 1),
                       se = runif(26)) %>%
    tidyr::crossing(trait = letters[1:3],
             type = c(1, 0, 0))

  hyprcoloc_res <- hyprcoloc_df(df)
  
  expect_true(inherits(hyprcoloc_res, "hyprcoloc"))
})
```
  

## Coloc
    
```{r function-coloc_run}
#' Run Bayesian enumeration colocalization using Coloc
#' 
#' This function is a wrapper around [coloc::coloc.abf()] that takes a dataframe as input, and performs colocalization under the single-causal-variant assumption. Coloc was described in Giambartolomei et al. (PLOS Genetics 2014; <https://doi.org/10.1371/journal.pgen.1004383>).
#' 
#' @param df Dataframe containing summary statistics at a single locus for two traits in a "long" format, with one row per variant per trait.
#' @param trait_col Column containing trait names
#' @param variant_col Column containing unique variant identifiers (Eg. rsids, chr:pos)
#' @param beta_col Column containing effect estimates
#' @param se_col Column containing standard errors
#' @param samplesize_col Column containing sample sizes
#' @param maf_col Column containing minor allele frequencies
#' @param type_col Column containing the type of each trait ("quant" for quantitative traits, "cc" for binary traits)
#' @param case_prop_col Column containing the proportion of cases for case control studies; this column is ignored for quantitative traits
#' @param p1 Prior probability a SNP is associated with trait 1, default 1e-4
#' @param p2 Prior probability a SNP is associated with trait 2, default 1e-4
#' @param p12 Prior probability a SNP is associated with both traits, default 1e-5
#' @param ... Arguments passed to [coloc::coloc.abf()]
#'
#' @return A list containing coloc results.
#' - `summary` is a named vector containing the number of snps, and the posterior probabilities of the 5 colocalization hypotheses
#' - `results` is an annotated version of the input data containing log approximate Bayes Factors and posterior probability of each SNP being causal if H4 is true.
#' 
#' @concept genomics
#' @family {colocalization}
#' @export

coloc_run <- function(df, trait_col = trait, variant_col = rsid, beta_col = beta, se_col = se, samplesize_col = samplesize, maf_col = maf, type_col = type, case_prop_col = case_prop, p1 = 1e-4, p2 = 1e-4, p12 = 1e-5, ...) {
  
df <- df %>% 
    select(trait = {{trait_col}}, maf = {{maf_col}}, type = {{type_col}}, variant_id = {{variant_col}}, beta = {{beta_col}}, se = {{se_col}}, samplesize = {{samplesize_col}}, case_prop = {{case_prop_col}}) %>%
    add_count(variant_id) %>%
    filter(n == 2)
  
  trait_dfs <- df %>%
    distinct(trait)
  
  if(nrow(trait_dfs) != 2) {
    cli::cli_abort("The input dataframe must contain only two traits")
  }
  
  trait1 <- df %>%
    filter(trait == trait_dfs$trait[1]) %>%
    distinct(variant_id, .keep_all = TRUE)
  
  trait2 <- df %>%
    filter(trait == trait_dfs$trait[2]) %>%
    distinct(variant_id, .keep_all = TRUE)
  
  trait1_dataset <- list(beta = trait1$beta, #If log_OR column is full of NAs then use beta column instead
                          varbeta = trait1$se^2,
                          # pvalues = trait1$pval,
                          type = unique(trait1$type), 
                          snp = trait1$variant_id,
                          N = trait1$samplesize,
                          # {if(unique(trait1$type) == "cc") {s = trait1$case_prop[1]}},
                          MAF = trait1$maf)
  
  trait2_dataset <- list(beta = trait2$beta, #If log_OR column is full of NAs then use beta column instead
                          varbeta = trait2$se^2,
                          # pvalues = trait2$pval,
                          type = unique(trait2$type), 
                          snp = trait2$variant_id,
                          N = trait2$samplesize,
                         # {if(unique(trait2$type) == "cc") {s = trait1$case_prop[2]}},
                          MAF = trait2$maf)
  
  suppressWarnings(coloc_res <- coloc::coloc.abf(dataset1 = trait1_dataset, dataset2 = trait2_dataset, p1, p2, p12, ...))
  return(coloc_res)
}
```
  
```{r example-coloc_run}
#' \dontrun{
#' coloc_run(locus_df)
#' }
```
  
```{r tests-coloc_run}
test_that("coloc_run works", {
  expect_true(inherits(coloc_run, "function")) 
})

test_that("coloc_run returns a list", {
  
  locus_df1 <- tibble::tibble(trait = "A", rsid = letters, beta = runif(26, min = -1), se = runif(26, max = 0.2), p_value = runif(1, min = 1/1e5, max = 0.99), samplesize = 10000, maf = runif(26), type = "quant", case_prop = NA)
  locus_df2 <- tibble::tibble(trait = "B", rsid = letters, beta = runif(26, min = -1), se = runif(26, max = 0.2), p_value = runif(1, min = 1/1e5, max = 0.99), samplesize = 10000, maf = runif(26), type = "cc", case_prop = 0.2)
  
  locus_df <- dplyr::bind_rows(locus_df1, locus_df2)
  
  coloc_res <- coloc_run(locus_df)
  
  expect_true(inherits(coloc_res, "list")) 
})
```
  
  
  
---
  
# Finemapping

Finemapping is an approach for identifying the putative causal variant(s) at a locus identified in a GWAS. Like colocalization, finemapping methods make different assumptions about the configuration of causal variant(s) at the locus.

## Bayesian finemapping

This function implements the simple Bayesian finemapping approach described in Mallard et al. (Nature Genetics 2012; <https://doi.org/10.1038/ng.2435>), adapted in Graham et al. (Nature 2021; <https://doi.org/10.1038/s41586-021-04064-3>). This method assumes a single causal variant configuration at the locus.
    
```{r function-calc_credset}
#' Perform Bayesian finemapping
#' 
#' Description
#' 
#' @param df Dataframe containing GWAS summary statistics
#' @param locus_marker_col Column containing a locus-level identifier 
#' @param effect_col Column containing effect estimates
#' @param se_col Column containing standard errors fo the effect estimates
#' @param samplesize_col Column containing sample sizes
#' @param cred_interval Credible interval for the fine-mapped credible sets (default = 0.99; 0.95 is another common but artbitrarily determined interval)
#'
#' @return A data.frame containing credible sets at each locus. For each variant within the credible set, the prior probability of being the casual variant is provided.
#' 
#' @export
#' @family {finemapping}
#' @concept genomics

calc_credset <- function(df, locus_marker_col = locus_marker, effect_col = effect, se_col = std_err, samplesize_col = samplesize, cred_interval = 0.99) {
  df %>%
    group_by({{ locus_marker_col }}) %>%
    mutate(bf = exp(0.5 * ({{ effect_col }}^2 / {{ se_col }}^2 - log({{ samplesize_col }})))) %>%
    mutate(posterior_prob = bf / sum(bf)) %>%
    arrange(desc(posterior_prob)) %>%
    mutate(cum_sum = cumsum(posterior_prob)) %>%
    group_by({{ locus_marker_col }}) %>%
    filter(cum_sum <= cred_interval | posterior_prob > cred_interval) %>%
    select(-cum_sum) %>%
    ungroup()
}
```
  
```{r example-calc_credset}
#' \dontrun{
#' calc_credset(gwas_df)
#' }
```
  
```{r tests-calc_credset}
test_that("calc_credset works", {
  expect_true(inherits(calc_credset, "function")) 
})
```

---    
  
# Gene-based Testing

GWAS summary statistics can be used to perform gene-based testing for associations with the trait/phenotype of interest, rather than SNP/variant-level associations found in GWAS.

## MAGMA

This function provides a wrapper to MAGMA, which performs gene-based testing from GWAS summary statistics. Details of MAGMA described in de Leeuw et al. (PLoS Cumputational Biology 2015; <https://doi.org/10.1371/journal.pcbi.1004219>). The MAGMA binary and reference files are available from the Complex Trait Genetics lab (<https://ctg.cncr.nl/software/magma>).
    
```{r function-magmar}
#' Run MAGMA gene-based analysis
#' 
#' This function provides a wrapper to MAGMA, which performs gene-based testing from GWAS summary statistics. Details of MAGMA described in de Leeuw et al. (PLoS Cumputational Biology 2015; <https://doi.org/10.1371/journal.pcbi.1004219>). The MAGMA binary and reference files are available from the Complex Trait Genetics lab (<https://ctg.cncr.nl/software/magma>).
#' 
#' @param sumstats_df Dataframe containing GWAS summary statistics
#' @param pval_col Column containing p-values
#' @param snp_col Column containing rsids
#' @param samplesize_col Column containing sample size
#' @param magma_bin Path to MAGMA binary
#' @param bfile Path to reference data in plink `bfile` format (path should not include the extensions)
#' @param gene_file Path to file containing gene locations
#' @param out_file Output directory + file prefix
#'
#' @return Path to MAGMA results file
#' @concept genomics
#' @export
#' 
magmar <- function(sumstats_df, pval_col = p_value, snp_col = rsid, samplesize_col = samplesize, magma_bin, bfile, gene_file, out_file) {
  cli::cli_progress_step("Writing summary statistics to temporary file")
  sumstats_file <- fs::file_temp()
  sumstats_df %>%
    select(SNP = {{ snp_col }}, P = {{ pval_col }}, N = {{ samplesize_col }}) %>%
    vroom::vroom_write(sumstats_file)


  cli::cli_progress_step("Running MAGMA")

  # create output path if it doesn't exist
  fs::dir_create(fs::path_dir(out_file))

  processx::run(magma_bin,
    args = c(
      "--bfile", bfile,
      "--gene-annot", gene_file,
      "--pval", sumstats_file, "ncol=N",
      "--gene-model", "snp-wise=mean",
      "--out", out_file
    ),
    error_on_status = FALSE,
    echo_cmd = TRUE,
    echo = TRUE
  )

  genes_out <- paste0(out_file, ".genes.out")
  genes_raw <- paste0(out_file, ".genes.raw")

  return(
    c("genes_out" = genes_out)
  )
}
```
  
```{r example-magmar}
#' \dontrun{
#' magmar(sumstats_df, magma_bin = "/path/to/magma", bfile = "/path/to/bfiles", gene_file = "/path/to/genes", out_file = "magma_output")
#' 
```
  
```{r tests-magmar}
test_that("magmar works", {
  expect_true(inherits(magmar, "function")) 
})
```
    
---
# Heritability

## LDAK
    
```{r function-ldak_h2}
#' Calculate heritability using LDAK
#' 
#' This function wraps LDAK, a command-line tool for estimating heritability. The tool and associated reference files can be download from the LDAK website (<https://ldak.org/>). The method is described in Zhang et al. (Nature Communications 2021; <https://doi.org/10.1038/s41467-021-24485-y).
#' 
#' @param sumstats_file Path to "munged" GWAS summary statistics file in LDSC format. The current implementation of this function requires rsids to link to other LDAK files. 
#' @param ldak_bin Path to LDAK binary
#' @param ldak_tagfile Path to LDAK tagfile
#' @param sample_prev Sample prevalence of cases (for case-control studies), `NULL` (default) for quantitative traits
#' @param population_prev Population prevalence of cases in the sample (for case-control studies), `NULL` (default) for quantitative traits
#' @param hm3_file Path to hm3 file containing 
#' @param ldak_cutoff Minor allele frequency cutoff (default = 0.01)
#'
#' @return List of dataframes containing LDAK results
#' @concept genomics
#' @family {heritability}
#' @import stringr
#' @export

ldak_h2 <- function(sumstats_file, ldak_bin, ldak_tagfile, sample_prev = NULL, population_prev = NULL, hm3_file, ldak_cutoff = 0.01) {
  # format paths
  cli::cli_progress_step("Formatting paths")
  ldak_bin <- fs::path_abs(ldak_bin)
  ldak_tagfile <- fs::path_abs(ldak_tagfile)
  ldak_in <- fs::file_temp()
  ldak_dir <- fs::path_temp()
  
  # Category annotations
  ldak_annotations <- glue::glue("1 Coding_UCSC*
2 Coding_UCSC.extend.500
3 Conserved_LindbladToh*
4 Conserved_LindbladToh.extend.500
5 CTCF_Hoffman*
6 CTCF_Hoffman.extend.500
7 DGF_ENCODE*
8 DGF_ENCODE.extend.500
9 DHS_peaks_Trynka
10 DHS_Trynka*
11 DHS_Trynka.extend.500
12 Enhancer_Andersson*
13 Enhancer_Andersson.extend.500
14 Enhancer_Hoffman*
15 Enhancer_Hoffman.extend.500
16 FetalDHS_Trynka*
17 FetalDHS_Trynka.extend.500
18 H3K27ac_Hnisz*
19 H3K27ac_Hnisz.extend.500
20 H3K27ac_PGC2*
21 H3K27ac_PGC2.extend.500
22 H3K4me1_peaks_Trynka
23 H3K4me1_Trynka*
24 H3K4me1_Trynka.extend.500
25 H3K4me3_peaks_Trynka
26 H3K4me3_Trynka*
27 H3K4me3_Trynka.extend.500
28 H3K9ac_peaks_Trynka
29 H3K9ac_Trynka*
30 H3K9ac_Trynka.extend.500
31 Intron_UCSC*
32 Intron_UCSC.extend.500
33 PromoterFlanking_Hoffman*
34 PromoterFlanking_Hoffman.extend.500
35 Promoter_UCSC*
36 Promoter_UCSC.extend.500
37 Repressed_Hoffman*
38 Repressed_Hoffman.extend.500
39 SuperEnhancer_Hnisz*
40 SuperEnhancer_Hnisz.extend.500
41 TFBS_ENCODE*
42 TFBS_ENCODE.extend.500
43 Transcr_Hoffman*
44 Transcr_Hoffman.extend.500
45 TSS_Hoffman*
46 TSS_Hoffman.extend.500
47 UTR_3_UCSC*
48 UTR_3_UCSC.extend.500
49 UTR_5_UCSC*
50 UTR_5_UCSC.extend.500
51 WeakEnhancer_Hoffman*
52 WeakEnhancer_Hoffman.extend.500
53 Super_Enhancer_Vahedi*
54 Super_Enhancer_Vahedi.extend.500
55 Typical_Enhancer_Vahedi*
56 Typical_Enhancer_Vahedi.extend.500
57 GERP.NS
58 GERP.RSsup4
59 MAF_Adj_Predicted_Allele_Age
60 MAF_Adj_LLD_AFR
61 Recomb_Rate_10kb
62 Nucleotide_Diversity_10kb
63 Backgrd_Selection_Stat
64 CpG_Content_50kb
65 LDAK_Weightings
66 Base_Category") %>%
  read_delim(col_names = c("category", "annotation"), delim = " ") %>%
  mutate(binary = str_detect(annotation, "\\*")) %>%
  mutate(annotation = str_replace(annotation, "\\*", ""))

  # read files
  cli::cli_progress_step("Reading files")
  hm3_df <- vroom::vroom(hm3_file, col_names = c("SNP", "Predictor"), col_select = c(1:2), col_types = "cc")
  sumstats_df <- vroom::vroom(sumstats_file, show_col_types = FALSE)
  phenotype <- fs::path_file(sumstats_file)


  # write summary statistics
  cli::cli_progress_step("Writing summary statistics")
  sumstats_df %>%
    inner_join(hm3_df, by = c("SNP" = "SNP")) %>%
    select(Predictor, A1, A2, n = N, Z) %>%
    filter(is.finite(Z)) %>%
    vroom::vroom_write(ldak_in)

  cli::cli_progress_step("Running LDAK")
  processx::run(ldak_bin,
    args = c(
      "--sum-hers", phenotype,
      "--summary", ldak_in,
      "--tagfile", ldak_tagfile,
      "--check-sums", "NO",
      if(!is.null(population_prev)){c("--prevalence", population_prev)},
      if(!is.null(sample_prev)){c("--ascertainment", sample_prev)},
      "--cutoff", ldak_cutoff
    ),
    error_on_status = FALSE,
    echo_cmd = TRUE,
    echo = TRUE,
    wd = ldak_dir
  )

  h2_res <- vroom::vroom(fs::dir_ls(ldak_dir, glob = "*.hers*"), show_col_types = FALSE, col_names = c("component", "h2", "h2_sd", "influence", "influence_sd"), skip = 1) %>%
    mutate(category = str_match(component, "\\d+")) %>%
    readr::type_convert() %>%
    left_join(ldak_annotations)
  cat_res <- vroom::vroom(fs::dir_ls(ldak_dir, glob = "*.cats*"), col_names = c("component", "heritability", "sd"), show_col_types = FALSE, skip = 1) %>%
    mutate(category = str_match(component, "\\d+")) %>%
    readr::type_convert() %>%
    left_join(ldak_annotations)
  share_res <- vroom::vroom(fs::dir_ls(ldak_dir, glob = "*.share*"), col_names = c("component", "share", "sd"), show_col_types = FALSE, skip = 1) %>%
    mutate(category = str_match(component, "\\d+")) %>%
    readr::type_convert() %>%
    left_join(ldak_annotations)
  enrich_res <- vroom::vroom(fs::dir_ls(ldak_dir, glob = "*.enrich*"), col_names = c("component", "share", "share_sd", "expected", "enrichment", "enrichment_sd"), show_col_types = FALSE, skip = 1) %>%
    mutate(category = str_match(component, "\\d+")) %>%
    readr::type_convert() %>%
    left_join(ldak_annotations)
  # extra_res <- vroom::vroom(fs::dir_ls(ldak_dir, glob = "*.extra*"), show_col_types = FALSE, skip = 1)

  return(list(
    h2 = h2_res,
    cat = cat_res,
    share = share_res,
    enrich = enrich_res
  ))
}
```
  
```{r example-ldak_h2}
#' \dontrun{
#' ldak_h2(sumstats_file = "/path/to/munged_sumstats", ldak_bin = "/path/to/ldak", ldak_tagfile = "/pat/to/tagfile",  hm3_file = "/path/to/hm3")
#' }
```
  
```{r tests-ldak_h2}
test_that("ldak_h2 works", {
  expect_true(inherits(ldak_h2, "function")) 
})
```
  

```{r development-inflate, eval=FALSE}
# Run but keep eval=FALSE to avoid infinite loop
# Execute in the console directly

fusen::inflate(flat_file = "dev/flat_genomics_functions.Rmd", vignette_name = "Genomics Functions")
```

