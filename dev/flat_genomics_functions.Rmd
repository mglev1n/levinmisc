---
title: "flat_genomics_functions.Rmd empty"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r development, include=FALSE}
library(testthat)
```

```{r development-load}
# Load already included functions if relevant
pkgload::load_all(export_all = FALSE)
```

# Plotting

These convenience functions are useful for creating plots from GWAS summary statistics.

## Manhattan plots

The `gg_manhattan_df` function is used to create Manhattan plots. This function can optionally annotated the plot with additional information (eg. gene name, rsid) by using the `annotation_df` amd `label_col` arguments.
    
```{r function-gg_manhattan_df}
#' Create a Manhattan Plot
#'
#' This function is a wrapper around `ggfastman::fast_manhattan` which allows for the creation of a Manhattan plot from a dataframe containing GWAS summary statistics.
#'
#' @param sumstats_df Dataframe containing GWAS summary statistics
#' @param chr_col Name of chromosome column
#' @param pos_col Name of position column
#' @param pval_col Name of p-value column
#' @param pval_threshold Threshold for plotting p-values (p-values greater than this value are excluded from the plot; default = `0.001`)
#' @param annotation_df Optional dataframe containing chromosome, position, and annotation labels
#' @param label_col Name of column in `annotation_df` containing annotations to include on the plot
#' @param build (string) One of "hg18", "hg19", or "hg38" (passed to `ggfastman`)
#' @param color1 (string) Color for odd-numbered chromosomes (passed to `ggfastman`)
#' @param color2 (string) Color for even-numbered chromosomes (passed to `ggfastman`)
#' @param speed (string) One of "slow", "fast", or "ultrafast"; passed to `ggfastman` to control plotting speed
#' @param ... Arguments passed to `ggfastman::fast_manhattan`
#'
#' @return A ggplot2 object
#' @export
#' @import dplyr ggplot2
#' @concept genomics
#' @family {plotting}

gg_manhattan_df <- function(sumstats_df, annotation_df = NULL, chr_col = chromosome, pos_col = position, pval_col = p_value, pval_threshold = 0.001, label_col = gene, build = "hg19", color1 = "#045ea7", color2 = "#82afd3", speed = "slow", ...) {
  if (!is.null((annotation_df))) {
    df <- sumstats_df %>%
      select(chr = {{ chr_col }}, pos = {{ pos_col }}, pvalue = {{ pval_col }}) %>%
      filter(pvalue < pval_threshold) %>%
      collect() %>%
      as_tibble() %>%
      mutate(across(.cols = everything(), as.numeric)) %>%
      tidyr::drop_na() %>%
      left_join(annotation_df %>% select(chr = {{ chr_col }}, pos = {{ pos_col }}, label = {{ label_col }})) %>%
      mutate(highlight = case_when(
        pvalue < 5e-8 ~ "#990000",
        TRUE ~ NA_character_
      ))
  } else {
    df <- sumstats_df %>%
      select(chr = {{ chr_col }}, pos = {{ pos_col }}, pvalue = {{ pval_col }}) %>%
      filter(pvalue < pval_threshold) %>%
      collect() %>%
      as_tibble() %>%
      mutate(across(.cols = everything(), as.numeric)) %>%
      tidyr::drop_na() %>%
      mutate(highlight = case_when(
        pvalue < 5e-8 ~ "#990000",
        TRUE ~ NA_character_
      ))
  }

  cli::cli_alert_info("Creating Manhattan Plot")
  if (!is.null((annotation_df))) {
    max_log10_p <- -log10(min(df$pvalue))

    plot <- df %>%
      ggfastman::fast_manhattan(
        build = build,
        color1 = color1,
        color2 = color2,
        pointsize = pointsize,
        speed = speed,
        ...
      ) +
      geom_hline(yintercept = -log10(5e-8), linetype = "dotted") +
      ggrepel::geom_text_repel(
        data = . %>%
          filter(!is.na(label)),
        aes(label = label),
        color = "black",
        force_pull = 0, # do not pull toward data points
        nudge_y = 10,
        direction = "x",
        angle = 90,
        hjust = 0,
        segment.size = 0.2,
        segment.curvature = -1e-20,
        segment.angle = 175,
        ylim = c(max_log10_p + 10, NA),
        max.overlaps = 50
      )
  } else {
    plot <- df %>%
      ggfastman::fast_manhattan(
        build = build,
        color1 = color1,
        color2 = color2,
        pointsize = pointsize,
        speed = speed,
        ...
      ) +
      geom_hline(yintercept = -log10(5e-8), linetype = "dotted")
  }

  plot <- plot +
    ggplot2::scale_y_continuous(expand = expansion(mult = c(0.01, 0.30)), name = "-log<sub>10</sub>(p-value)") +
    theme_bw(base_size = 16) +
    theme(
      panel.grid = element_blank(),
      axis.title.y = ggtext::element_markdown()
    )

  return(plot)
}
```
  
```{r example-gg_manhattan_df}
#' \dontrun{
#' gg_manhattan_df(sumstats_df)
#' }
```
  
```{r tests-gg_manhattan_df}
test_that("gg_manhattan_df works", {
  expect_true(inherits(gg_manhattan_df, "function"))
})

test_that("gg_manhattan_df returns a ggplot object", {
  locus_df <- tibble(position = sample.int(1000, 100)) %>%
    tidyr::crossing(chromosome = 1:22) %>%
    rowwise() %>%
    mutate(p_value = runif(1, min = 1/1e100, max = 0.001)) %>%
    mutate(label = "Test")

  plot_res <- locus_df %>%
    gg_manhattan_df(chr_col = chromosome, pos_col = position, pval_col = p_value, speed = "ultrafast")
  expect_s3_class(plot_res, "ggplot")

  plot_res <- locus_df %>%
    gg_manhattan_df(chr_col = chromosome, pos_col = position, pval_col = p_value, annotation_df = locus_df, label_col = label)
  expect_s3_class(plot_res, "ggplot")
})
```

  
## QQ plots

The `gg_qq_df` function can be used to generate a qq plot to visually evaluate for test statistic inflation, and calculate lambda GC to quantify any inflation.
    
```{r function-gg_qq_df}
#' Create a QQ plot
#'
#' This function is a wrapper around `ggfastman::fast_qq` which allows for the creation of a QQ plot from a dataframe containing GWAS summary statistics.
#'
#' @param sumstats_df Dataframe containing GWAS summary statistics
#' @param pval_col Name of p-value column
#' @param ... Arguments passed to `ggfastman::fast_qq`
#'
#' @return A ggplot2 object
#'
#' @export
#' @import dplyr ggplot2
#' @concept genomics
#' @family {plotting}

gg_qq_df <- function(sumstats_df, pval_col = p_value, ...) {
  df <- sumstats_df %>%
    select(pvalue = {{ pval_col }}) %>%
    collect() %>%
    as_tibble() %>%
    mutate(across(.cols = everything(), as.numeric)) %>%
    pull(pvalue)

  cli::cli_alert_info("Creating QQ Plot")
  plot <- df %>%
    ggfastman::fast_qq(...)

  return(plot)
}
```
  
```{r example-gg_qq_df}
#' \dontrun{
#' gg_qq_df(sumstats_df)
#' }
```
  
```{r tests-gg_qq_df}
test_that("gg_qq_df works", {
  expect_true(inherits(gg_qq_df, "function"))
})

test_that("gg_qq_df returns a ggplot object", {
  plot_res <- tibble(pval = runif(1000)) %>%
    gg_qq_df(pval_col = pval)
  expect_s3_class(plot_res, "ggplot")
})
```
  
---

# Annotation

These convenience functions are useful for adding additional information to GWAS summary stastics.

## Add rsids

This function can be used rapidly add rsids to GWAS summary statistics by chromosome:position.
    
```{r function-annotate_rsids}
#' Annotate a dataframe containing genomic coordinates with rsids
#' 
#' This function can be used rapidly add rsids to GWAS summary statistics or any other dataframe containing genomic coordinates (eg. chromosome and position). This is a rapid function that does not explicitly account for differences in variants at each position, strand flips, etc.)
#' 
#' @param df Dataframe containing genomic coordinates to annotate with rsid
#' @param dbSNP Bioconductor object containing SNP locations and alleles to be used for annotation (default: `SNPlocs.Hsapiens.dbSNP144.GRCh37::SNPlocs.Hsapiens.dbSNP144.GRCh37`)
#' @param chrom_col Chromosome column 
#' @param pos_col Position column
#'
#' @return A dataframe containing the original contents, with an additional `rsid` column.
#' 
#' @export
#' @concept genomics 
#' @family {annotation}

annotate_rsids <- function(df, dbSNP = SNPlocs.Hsapiens.dbSNP144.GRCh37::SNPlocs.Hsapiens.dbSNP144.GRCh37, chrom_col = Chromosome, pos_col = Position) {
  if (sum(stringr::str_detect(names(df), "rsid")) > 0) {
    cli::cli_abort("A column named 'rsid' is already present")
  }

  df <- df %>%
    dplyr::rename(chrom = {{ chrom_col }}) %>%
    dplyr::mutate(chrom = as.character(chrom)) %>%
    # mutate(chrom = glue::glue("{chrom}")) %>%
    dplyr::rename(start = {{ pos_col }}) %>%
    dplyr::mutate(end = start)

  # return(df)

  df_annotated <- df %>%
    dplyr::group_split(chrom) %>%
    purrr::map_dfr(function(df) {
      chrom <- df$chrom[1]

      cli::cli_alert_info("Annotating chromosome {chrom}")

      df_granges <- df %>%
        GenomicRanges::makeGRangesFromDataFrame(keep.extra.columns = TRUE, starts.in.df.are.0based = FALSE)

      snps_granges <- BSgenome::snpsByOverlaps(dbSNP, df_granges) %>%
        unique()

      plyranges::join_overlap_left_directed(df_granges, snps_granges) %>%
        as.data.frame() %>%
        mutate(seqnames = as.character(seqnames))
    })

  df_annotated %>%
    dplyr::rename(
      {{ chrom_col }} := seqnames,
      {{ pos_col }} := start
    ) %>%
    # dplyr::mutate({{ chr_col }} := as.numeric({{ chr_col }})) %>%
    # dplyr::mutate({{ pos_col }} := as.numeric({{ pos_col }})) %>%
    dplyr::rename(rsid = RefSNP_id) %>%
    dplyr::select(-end, -width, -strand, -alleles_as_ambig) %>%
    dplyr::select(rsid, everything()) %>%
    readr::type_convert(col_types = readr::cols())
}
```
  
```{r example-annotate_rsids}
#' \dontrun{
#' annotate_rsids(sumstats_df)
#' }
```
  
```{r tests-annotate_rsids}
test_that("annotate_rsids works", {
  expect_true(inherits(annotate_rsids, "function")) 
})

test_that("annotate_rsids returns a tibble", {
  df <- tibble(Chromosome = 1) %>%
    tidyr::crossing(Position = 1e4:1e5)
  rsids_res <- annotate_rsids(df)
  expect_s3_class(rsids_res, "data.frame")
})
```
  
---

# GWAS Meta-analysis

GWAS summary statistics from multiple studies can be combined using meta-analysis. The following functions are useful for orchestrating GWAS meta-analysis using R.

## METAL

METAL (<https://github.com/statgen/METAL>) is a common command-line tool for performing GWAS meta-analysis. The following functions can be used to configure and run METAL directly from R.

## Configure METAL
    
```{r function-metal_config}
#' Create a configuration file for METAL
#' 
#' This function can be used to generate a configuration for METAL, a tool for performing meta-analysis of GWAS summary statistics <https://github.com/statgen/METAL>. The file created by this function can be used to run a meta-analysis. Details of the arguments to METAL are described in the METAL documentation: <https://genome.sph.umich.edu/wiki/METAL_Documentation>.
#' 
#' @param config_name (string) Name of the configuration
#' @param output_dir (path) Path to output directory where GWAS meta-analysis data should be stored
#' @param study_files (vector) Character vector of paths to summary statistics that should be included in the GWAS
#' @param SCHEME (string) Either "SAMPLESIZE" or "STDERR" (default), corresponding to the METAL analysis scheme
#' @param AVERAGEFREQ (string) Either "ON" (default) or "OFF", allowing METAL to report the mean effect allele frequency across files
#' @param MINMAXFREQ (string) Either "ON" (default) or "OFF", allowing METAL to report the min/max effect allele frequency across files
#' @param TRACKPOSITIONS (string) Either "ON" (default) or "OFF", allowing METAL to report chromosome/position in the output
#' @param MARKERLABEL (string) Column containing unique markers to analyze (this column must be named the same across all input files)
#' @param CHROMOSOMELABEL (string) Column containing chromosomes (this column must be named the same across all input files)
#' @param POSITIONLABEL (string) Column containing genomic positions (this column must be named the same across all input files)
#' @param EFFECT_ALLELE (string) Column containing effect alleles (this column must be named the same across all input files)
#' @param OTHER_ALLELE (string) Column containing non-effect alleles (this column must be named the same across all input files)
#' @param EFFECTLABEL (string) Column containing effect sizes corresponding to the effect allele (this column must be named the same across all input files)
#' @param STDERR (string) Column containing standard errors fo the effect estimate (this column must be named the same across all input files)
#' @param FREQLABEL (string) Column containing effect allele frequencies (this column must be named the same across all input files)
#' @param NCASE (string) Column containing number of cases (this column must be named the same across all input files)
#' @param NCONTROL (string) Column containing number of controls (this column must be named the same across all input files)
#' @param SAMPLESIZE (string) Column containing total samplesize (this column must be named the same across all input files)
#'
#' @return Path to METAL configuration file
#' @concept genomics
#' @family GWAS meta-analysis
#' @seealso Run GWAS meta-analysis using METAL: [levinmisc::metal_run()]
#' @export

metal_config <- function(config_name, output_dir, study_files, SCHEME = "STDERR", AVERAGEFREQ = "ON", MINMAXFREQ = "OFF", TRACKPOSITIONS = "ON", MARKERLABEL = "MARKER", CHROMOSOMELABEL = "CHROM", POSITIONLABEL = "POS", EFFECT_ALLELE = "EFFECT_ALLELE", OTHER_ALLELE = "OTHER_ALLELE", EFFECTLABEL = "BETA", STDERR = "SE", FREQLABEL = "EAF", NCASE = "N_CASE", NCONTROL = "N_CONTROL", SAMPLESIZE = "N") {
  
  fs::dir_create(output_dir, recurse = TRUE)

  config_outfile <- fs::path(output_dir, paste0(config_name, "_metal-config.txt"))
  meta_outfile <- fs::path(normalizePath(output_dir), config_name)

  study_files <- paste0(glue::glue("PROCESS {normalizePath(study_files)}"), collapse = "\n")

  config_text <- glue::glue(
    "SCHEME {SCHEME}
    AVERAGEFREQ {AVERAGEFREQ}
    MINMAXFREQ {MINMAXFREQ}
    TRACKPOSITIONs {TRACKPOSITIONS}
    MARKERLABEL {MARKERLABEL}
    CHROMOSOMELABEL {CHROMOSOMELABEL}
    POSITIONLABEL {POSITIONLABEL}
    ALLELELABELS {EFFECT_ALLELE} {OTHER_ALLELE}
    EFFECTLABEL {EFFECTLABEL}
    STDERR {STDERR}
    FREQLABEL {FREQLABEL}
    
    CUSTOMVARIABLE NCASE
    LABEL NCASE as {NCASE}
    
    CUSTOMVARIABLE NCONTROL
    LABEL NCONTROL as {NCONTROL}
    
    CUSTOMVARIABLE SAMPLESIZE
    LABEL SAMPLESIZE as {SAMPLESIZE}
    
    {study_files}
    
    OUTFILE {meta_outfile}_metal- .txt
    ANALYZE HETEROGENEITY
    
    QUIT
    "
  )

  readr::write_lines(x = config_text, file = config_outfile)

  return(config_outfile)
}
```
  
```{r example-metal_config}
#' \dontrun{
#' metal_config(config_name = "name-of-analysis", output_dir = "/path/to/output/", study_files = c("/path/to/sumstats_1.txt", "/path/to/sumstats_2.txt))
#' }
```
  
```{r tests-metal_config}
test_that("metal_config works", {
  expect_true(inherits(metal_config, "function")) 
})
```

## Run METAL
    
```{r function-metal_run}
#' Use METAL to run a GWAS meta-analysis
#' 
#' This function is a wrapper for METAL, a tool for performing meta-analysis of GWAS summary statistics <https://github.com/statgen/METAL>. Details of the arguments to METAL are described in the METAL documentation: <https://genome.sph.umich.edu/wiki/METAL_Documentation>.
#' 
#' @param config_file (path) Path to a METAL configuration file (this can be generated using [levinmisc::metal_config()])
#' @param metal_path (path) Path to the METAL binary
#'
#' @return Path to gzip-formatted text file containing meta-analysis summary statistics
#' @concept genomics
#' @family GWAS meta-analysis
#' @seealso Create a METAL configuration file: [levinmisc::metal_config()]
#' @export

metal_run <- function(config_file, metal_path) {
  metal_path <- normalizePath(metal_path)
  config_file <- normalizePath(config_file)

  processx::run(metal_path, args = config_file)
  output_file <- str_replace(config_file, "-config.txt", "-1.txt")

  processx::run("gzip", c("-f", output_file))

  output_file <- str_replace(output_file, ".txt", ".txt.gz")

  return(output_file)
}
```
  
```{r example-metal_run}
#' \dontrun{
#' metal_run(config_file = "config.txt", metal_path = "/path/to/metal_binary")
#' }
```
  
```{r tests-metal_run}
test_that("metal_run works", {
  expect_true(inherits(metal_run, "function")) 
})
```

## Run MR-MEGA
    
```{r function-mr_mega}
#' Perform multi-ancestry GWAS meta-analysis using MR-MEGA
#' 
#' This function is a wrapper around MR-MEGA, which uses meta-regression to combine GWAS summart statistics while accounting for study/population-specific components of genetic variation. The method was described in Magi et al. (Human Molecular Genetics 2017; <https://doi.org/10.1093/hmg/ddx280>), and the package can be obtained from the Estonian Genome Centre (<https://genomics.ut.ee/en/tools>).
#' 
#' @param sumstats_files List of files containing GWAS summary statistics. These files should all contain the same column header.
#' @param mr_mega_bin Path to MR-MEGA binary
#' @param marker_col Column containing unique markers for each variant
#' @param chr_col Column containing the chromosome
#' @param pos_col Column containing the position
#' @param effect_allele_col Column containing the effect allele
#' @param other_allele_col Column containing the non-effect allele
#' @param eaf_col Column containing effect allele frequencies
#' @param beta_col Column containing effect estimates
#' @param se_col Column containing standard errors
#' @param p_value_col Column containing p-value
#' @param samplesize_col Column containing sample size
#' @param n_pcs Number of genetic principal components to include in the meta-regression.
#'
#' @return A data.frame containing the GWAS summary statistics from the meta-regression
#' @concept genomics
#' @family GWAS meta-analysis
#' @export

mr_mega <- function(sumstats_files, mr_mega_bin, marker_col = MARKER, chr_col = CHROM, pos_col = POS, effect_allele_col = EFFECT_ALLELE, other_allele_col = OTHER_ALLELE, eaf_col = EAF, beta_col = BETA, se_col = SE, p_value_col = P, samplesize_col = N, n_pcs = 3) {
  # set shell for calling MR-MEGA
  shell <- ifelse(Sys.info()["sysname"] == "Windows", "cmd", "sh")

  # write sumstats to temporary .txt files and return list of locations
  cli::cli_alert_info("Writing input files")
  mrmega_sumstats <- map(sumstats_files, function(sumstats_file) {
    file <- fs::file_temp()
    study <- basename(sumstats_file)
    sumstats_file %>%
      vroom::vroom() %>%
      select(MARKERNAME = {{ marker_col }}, EA = {{ effect_allele_col }}, NEA = {{ other_allele_col }}, BETA = {{ beta_col }}, SE = {{ se_col }}, EAF = {{ eaf_col }}, N = {{ samplesize_col }}, CHROMOSOME = {{ chr_col }}, POSITION = {{ pos_col }}) %>%
      vroom::vroom_write(file)

    return(fs::path_abs(file))
  })

  # write mrmega.in file with information about temporary files
  cli::cli_alert_info("Writing MR-MEGA script")
  mrmega_infile <- fs::file_temp()
  mrmega_sumstats %>%
    glue::glue_collapse(sep = "\n") %>%
    readr::write_lines(mrmega_infile)

  # run MR-MEGA
  cli::cli_alert_info("Running MR-MEGA")
  mrmega_outfile <- fs::file_temp()

  # pcs <- length(sumstats_files) - 3

  processx::run(mr_mega_bin,
    c("-i", mrmega_infile, "--qt", "--pc", n_pcs, "-o", mrmega_outfile),
    echo_cmd = TRUE,
    echo = TRUE
  )

  # read results
  cli::cli_alert_info("Reading MR-MEGA results")
  mrmega_res <- vroom(paste0(mrmega_outfile, ".result")) %>%
    janitor::clean_names()

  return(mrmega_res)
}
```
  
```{r example-mr_mega}
#' \dontrun{
#' mr_mega(sumstats_files = list("/path/to/sumstats_1.txt.gz", "/path/to/sumstats_2.txt.gz), mr_mega_bin = "/path/to/MR-MEGA")
#' }
```
  
```{r tests-mr_mega}
test_that("mr_mega works", {
  expect_true(inherits(mr_mega, "function")) 
})
```
  

---

# Linkage Disequilibirium

## plink

The `plink_extract_ld` function is a wrapper around the `plink` v1.9 binary, which takes a list of variants and uses a reference panel to calculate the linkage disequilibrium among variants.

    
```{r function-plink_extract_ld}
#' Extract an LD matrix from a reference panel using plink 1.9
#'
#' @param df Dataframe containing variants to be included in the LD matrix; must contain SNP identifier and effect allele
#' @param snp_col Name of column containing SNP identifiers
#' @param effect_allele_col Name of column containing effect alleles (used when considering signed measures of LD like `r`)
#' @param metric LD metric - either `r` (which will return a signed correlation matrix) or `r2` (which will return squared correlations)
#' @param bfile Path to plink `bfile` that will be used to extract LD
#' @param threads Number of threads (default = 1)
#' @param memory Memory limit (default = 16000 MB)
#' @param plink_bin Path to plink executable
#'
#' @return A square matrix containing the pairwise correlations between genetic variants
#' @export
#' @concept genomics
#' @family {linkage disequilibrium}
#' 
plink_extract_ld <- function(df, snp_col, effect_allele_col, metric = "r", bfile, threads = 1, memory = 16000, 
                             plink_bin) {

  snp_id <- df %>% select(SNP = {{snp_col}}) %>% head(1) %>% pull(SNP)
  
  snp_file <- fs::file_temp(pattern = snp_id)

  ld_dir <- fs::path_temp(snp_id)
  
  fs::dir_create(ld_dir, recurse = TRUE)

  df %>%
    select(SNP = {{ snp_col }}, snp_ideffect_allele = {{ effect_allele_col }}) %>%
    write_tsv(snp_file, col_names = FALSE)

  cli::cli_alert_info("Extracting LD")
  
  processx::run(plink_bin,
    args = c(
      "--threads", threads,
      "--memory", 16000,
      "--bfile", bfile,
      "--extract", snp_file,
      "--a1-allele", snp_file,
      "2 1 '#'",
      paste0("--", metric), "square", "gz",
      "--out", fs::path(ld_dir, "LD")
    ),
    error_on_status = FALSE,
    echo_cmd = TRUE,
    echo = TRUE
  )

  ld_matrix <- data.table::fread(fs::path(ld_dir, "LD.ld.gz"), col.names = df %>% pull({{snp_col}})) %>%
    as.matrix()
  
  rownames(ld_matrix) <- df %>% pull({{snp_col}})
  
  return(ld_matrix)
}
```
  
```{r example-plink_extract_ld}
#' \dontrun{
#' plink_extract_ld(df, snp_col, effect_allele_col, metric = "r", bfile = "/path/to/reference/panel/", plink_bin = "/path/to/plink1.9")
#' }
```
  
```{r tests-plink_extract_ld}
test_that("plink_extract_ld works", {
  expect_true(inherits(plink_extract_ld, "function")) 
})
```
  

<!-- ```{r function-plink_extract_ld_possibly} -->
<!-- #' plink_extract_ld_possibly -->
<!-- #'  -->
<!-- #' An internal wrapper around plink_extract_ld_possibly to silently return `NULL` on error -->
<!-- #'  -->
<!-- #' @return -->
<!-- #'  -->
<!-- #' @noRd -->
<!-- plink_extract_ld_possibly <- purrr::possibly(levinmisc::plink_extract_ld) -->
<!-- ``` -->

<!-- ```{r example-plink_extract_ld_possibly} -->
<!-- #' \dontrun{ -->
<!-- #' plink_extract_ld_possibly() -->
<!-- #' } -->
<!-- ``` -->

<!-- ```{r tests-plink_extract_ld_possibly} -->
<!-- test_that("plink_extract_ld_possibly works", { -->
<!--   expect_true(inherits(plink_extract_ld_possibly, "function"))  -->
<!-- }) -->
<!-- ``` -->
  
---  
  
# Colocalization

Colocalization is a technique for evaluating the evidence supporting the presence of shared causal variant(s) at a given locus across two or more traits. Several methods of colocalization have been described, which generally leverage GWAS summary statistics across multiple traits. The methods use either proportional or enumeration approaches, which make different assumptions and test different hypotheses.

## HyPrColoc

This function is a convenience wrapper around [hyprcoloc::hyprcoloc()] that takes a dataframe as input, and performs mutli-trait colocalization using HyPrColoc, a Bayesian enumeration colocalization method which makes the assumption of a single causal variant at the locus. Details of the HyPrColoc method are described in Foley et al. (Nature Communications 2021; <https://doi.org/10.1038/s41467-020-20885-8>).

```{r function-hyprcoloc_df}
#' Run multi-trait colocalization using HyPrColoc
#' 
#' This function is a convenience wrapper around [hyprcoloc::hyprcoloc()] that takes a dataframe as input, and performs mutli-trait colocalization. Details of the HyPrColoc method are described in Foley et al. (Nature Communications 2021; <https://doi.org/10.1038/s41467-020-20885-8>).
#' 
#' @param df Dataframe containing summary statistics at a single locus, in a "long" format, with one row per variant per trait.
#' @param trait_col Column containing trait names
#' @param snp_col Column containing variant names (eg. rsid, marker_name), which should be consistent across studies
#' @param beta_col Column containing effect estimates from GWAS
#' @param se_col Column containing standard errors of the effect estimates
#' @param type_col Column containing the "type" of trait - this column should contain `1` for binary traits, and `0` for all others
#' @param ... Arguments passed to [hyprcoloc::hyprcoloc()]
#'
#' @return A list containing a data.frame of HyPrColoc results: each row is a cluster of colocalized traits or is coded NA (if no colocalization is identified)
#' @import hyprcoloc tidyr
#' @importFrom purrr possibly
#' @concept genomics
#' @family {colocalization}
#' @export

hyprcoloc_df <- function(df, trait_col = trait, snp_col = rsid, beta_col = beta, se_col = se, type_col = type, ...) {
  df <- df %>%
    select(trait = {{ trait_col }}, rsid = {{ snp_col }}, beta.exposure = {{ beta_col }}, se.exposure = {{ se_col }}, type = {{ type_col }}) %>%
    distinct(rsid, trait, .keep_all = TRUE) %>%
    tidyr::drop_na()

  # return(df)

  .betas <- df %>%
    select(rsid, beta.exposure, trait) %>%
    distinct(rsid, trait, .keep_all = TRUE) %>%
    pivot_wider(names_from = trait, values_from = beta.exposure) %>%
    tibble::column_to_rownames(var = "rsid") %>%
    tidyr::drop_na() %>%
    as.matrix()

  .ses <- df %>%
    select(rsid, se.exposure, trait) %>%
    distinct(rsid, trait, .keep_all = TRUE) %>%
    pivot_wider(names_from = trait, values_from = se.exposure) %>%
    tibble::column_to_rownames(var = "rsid") %>%
    tidyr::drop_na() %>%
    as.matrix()

  .ids <- rownames(.betas)

  .trait_names <- colnames(.betas)

  .binary <- df %>%
    select(trait, type) %>%
    unique() %>%
    pivot_wider(names_from = trait, values_from = type) %>%
    tidyr::drop_na() %>%
    as.matrix()

  .possibly_hyprcoloc <- possibly(hyprcoloc::hyprcoloc)
  # .safely_hyprcoloc <- purrr::safely(hyprcoloc::hyprcoloc)

  .result <- .possibly_hyprcoloc(.betas, .ses, trait.names = .trait_names, snp.id = .ids, binary.outcomes = .binary, ...)

  return(.result)

  # .result <- hyprcoloc(.betas, .ses, trait.names = .trait_names, snp.id = .ids, binary.outcomes = .binary, snpscores = TRUE, uniform.priors = FALSE)

  # .credible_set <- cred_sets(.result, value = 0.95)

  # return(list(.result, .credible_set))

  # hyprcoloc::cred.sets()
}
```
  
```{r example-hyprcoloc_df}
#' \dontrun{
#' hyprcoloc_df(gwas_results_df)
#' }
```
  
```{r tests-hyprcoloc_df}
test_that("hyprcoloc_df works", {
  expect_true(inherits(hyprcoloc_df, "function")) 
  
  df <- tibble::tibble(rsid = letters,
                       beta = runif(26, min = -1, max = 1),
                       se = runif(26)) %>%
    tidyr::crossing(trait = letters[1:3],
             type = c(1, 0, 0))

  hyprcoloc_res <- hyprcoloc_df(df)
  
  expect_true(inherits(hyprcoloc_res, "hyprcoloc"))
})
```
  

## Coloc
    
```{r function-coloc_run}
#' Run Bayesian enumeration colocalization using Coloc
#' 
#' This function is a wrapper around [coloc::coloc.abf()] that takes a dataframe as input, and performs colocalization under the single-causal-variant assumption. Coloc was described in Giambartolomei et al. (PLOS Genetics 2014; <https://doi.org/10.1371/journal.pgen.1004383>).
#' 
#' @param df Dataframe containing summary statistics at a single locus for two traits in a "long" format, with one row per variant per trait.
#' @param trait_col Column containing trait names
#' @param variant_col Column containing unique variant identifiers (Eg. rsids, chr:pos)
#' @param beta_col Column containing effect estimates
#' @param se_col Column containing standard errors
#' @param samplesize_col Column containing sample sizes
#' @param maf_col Column containing minor allele frequencies
#' @param type_col Column containing the type of each trait ("quant" for quantitative traits, "cc" for binary traits)
#' @param case_prop_col Column containing the proportion of cases for case control studies; this column is ignored for quantitative traits
#' @param p1 Prior probability a SNP is associated with trait 1, default 1e-4
#' @param p2 Prior probability a SNP is associated with trait 2, default 1e-4
#' @param p12 Prior probability a SNP is associated with both traits, default 1e-5
#' @param ... Arguments passed to [coloc::coloc.abf()]
#'
#' @return A list containing coloc results.
#' - `summary` is a named vector containing the number of snps, and the posterior probabilities of the 5 colocalization hypotheses
#' - `results` is an annotated version of the input data containing log approximate Bayes Factors and posterior probability of each SNP being causal if H4 is true.
#' 
#' @concept genomics
#' @family {colocalization}
#' @export

coloc_run <- function(df, trait_col = trait, variant_col = rsid, beta_col = beta, se_col = se, samplesize_col = samplesize, maf_col = maf, type_col = type, case_prop_col = case_prop, p1 = 1e-4, p2 = 1e-4, p12 = 1e-5, ...) {
  
df <- df %>% 
    select(trait = {{trait_col}}, maf = {{maf_col}}, type = {{type_col}}, variant_id = {{variant_col}}, beta = {{beta_col}}, se = {{se_col}}, samplesize = {{samplesize_col}}, case_prop = {{case_prop_col}}) %>%
    add_count(variant_id) %>%
    filter(n == 2)
  
  trait_dfs <- df %>%
    distinct(trait)
  
  if(nrow(trait_dfs) != 2) {
    cli::cli_abort("The input dataframe must contain only two traits")
  }
  
  trait1 <- df %>%
    filter(trait == trait_dfs$trait[1]) %>%
    distinct(variant_id, .keep_all = TRUE)
  
  trait2 <- df %>%
    filter(trait == trait_dfs$trait[2]) %>%
    distinct(variant_id, .keep_all = TRUE)
  
  trait1_dataset <- list(beta = trait1$beta, #If log_OR column is full of NAs then use beta column instead
                          varbeta = trait1$se^2,
                          # pvalues = trait1$pval,
                          type = unique(trait1$type), 
                          snp = trait1$variant_id,
                          N = trait1$samplesize,
                          # {if(unique(trait1$type) == "cc") {s = trait1$case_prop[1]}},
                          MAF = trait1$maf)
  
  trait2_dataset <- list(beta = trait2$beta, #If log_OR column is full of NAs then use beta column instead
                          varbeta = trait2$se^2,
                          # pvalues = trait2$pval,
                          type = unique(trait2$type), 
                          snp = trait2$variant_id,
                          N = trait2$samplesize,
                         # {if(unique(trait2$type) == "cc") {s = trait1$case_prop[2]}},
                          MAF = trait2$maf)
  
  suppressWarnings(coloc_res <- coloc::coloc.abf(dataset1 = trait1_dataset, dataset2 = trait2_dataset, p1 = p1, p2 = p2, p12 = p12, ...))
  return(coloc_res)
}
```
  
```{r example-coloc_run}
#' \dontrun{
#' coloc_run(locus_df)
#' }
```
  
```{r tests-coloc_run}
test_that("coloc_run works", {
  expect_true(inherits(coloc_run, "function")) 
})

test_that("coloc_run returns a list", {
  
  locus_df1 <- tibble::tibble(trait = "A", rsid = letters, beta = runif(26, min = -1), se = runif(26, max = 0.2), p_value = runif(1, min = 1/1e5, max = 0.99), samplesize = 10000, maf = runif(26), type = "quant", case_prop = NA)
  locus_df2 <- tibble::tibble(trait = "B", rsid = letters, beta = runif(26, min = -1), se = runif(26, max = 0.2), p_value = runif(1, min = 1/1e5, max = 0.99), samplesize = 10000, maf = runif(26), type = "cc", case_prop = 0.2)
  
  locus_df <- dplyr::bind_rows(locus_df1, locus_df2)
  
  coloc_res <- coloc_run(locus_df)
  
  expect_true(inherits(coloc_res, "list")) 
})
```
  
  
  
---
  
# Finemapping

Finemapping is an approach for identifying the putative causal variant(s) at a locus identified in a GWAS. Like colocalization, finemapping methods make different assumptions about the configuration of causal variant(s) at the locus.

## Bayesian finemapping

This function implements the simple Bayesian finemapping approach described in Mallard et al. (Nature Genetics 2012; <https://doi.org/10.1038/ng.2435>), adapted in Graham et al. (Nature 2021; <https://doi.org/10.1038/s41586-021-04064-3>). This method assumes a single causal variant configuration at the locus.
    
```{r function-calc_credset}
#' Perform Bayesian finemapping using the Approximate Bayes Factor approach
#' 
#' Description
#' 
#' @param df Dataframe containing GWAS summary statistics
#' @param locus_marker_col Column containing a locus-level identifier 
#' @param effect_col Column containing effect estimates
#' @param se_col Column containing standard errors fo the effect estimates
#' @param samplesize_col Column containing sample sizes
#' @param cred_interval Credible interval for the fine-mapped credible sets (default = 0.99; 0.95 is another common but artbitrarily determined interval)
#'
#' @return A data.frame containing credible sets at each locus. For each variant within the credible set, the prior probability of being the casual variant is provided.
#' 
#' @export
#' @family {finemapping}
#' @concept genomics

calc_credset <- function(df, locus_marker_col = locus_marker, effect_col = effect, se_col = std_err, samplesize_col = samplesize, cred_interval = 0.99) {
  df %>%
    group_by({{ locus_marker_col }}) %>%
    mutate(bf = exp(0.5 * ({{ effect_col }}^2 / {{ se_col }}^2 - log({{ samplesize_col }})))) %>%
    mutate(posterior_prob = bf / sum(bf)) %>%
    arrange(desc(posterior_prob)) %>%
    mutate(cum_sum = cumsum(posterior_prob)) %>%
    group_by({{ locus_marker_col }}) %>%
    filter(cum_sum <= cred_interval | posterior_prob > cred_interval) %>%
    select(-cum_sum) %>%
    ungroup()
}
```
  
```{r example-calc_credset}
#' \dontrun{
#' calc_credset(gwas_df)
#' }
```
  
```{r tests-calc_credset}
test_that("calc_credset works", {
  expect_true(inherits(calc_credset, "function")) 
})
```

## CARMA

This function implements the CARMA finemapping approach described in Yang et al. (Nature Genetics 2023; <https://doi.org/10.1038/s41588-023-01392-0>). This method relaxes the single causal variant assumption, identifying independent credible sets at each fine-mapped locus.
    
```{r function-run_carma}
#' Perform Bayesian finemapping using CARMA
#' 
#' This function is a wrapper around `CARMA::CARMA()` that takes a dataframe containing variants at a locus and performs Bayesian finemapping. The function requires a plink-formatted LD reference panel (`bfile`), which will be used to generate a signed LD matrix at the locus. CARMA was described in Yang et al. (Nature Genetics 2023; <https://doi.org/10.1038/s41588-023-01392-0>)
#'
#' @param df Dataframe containing variants at a locus for finemapping
#' @param snp_col Name of column containing SNP identifiers
#' @param z_col Name of column containing signed Z-scores (relative to effect allele)
#' @param effect_allele_col Name of column containing effect alleles
#' @param bfile Path to plink `bfile` of reference panel that will be used to extract LD
#' @param threads Number of threads (default = 1)
#' @param memory Memory limit (default = 16000 MB)
#' @param plink_bin Path to plink executable
#'
#' @return A dataframe containing the input dataframe, and additional columns denoting which credible set (`CS`) each variant belongs to, as well as the posterior inclusion probability (`PIP`), and an `ld_error` column noting whether there were problems generating the LD matrix that limited fine-mapping.
#' 
#' @export
#' @family {finemapping}
#' @concept genomics

run_carma <- function(df, snp_col, z_col, effect_allele_col, bfile, threads = 1, memory = 16000, plink_bin) {
  
  sumstat <- df
  
  plink_extract_ld_possibly <- purrr::possibly(levinmisc::plink_extract_ld) 
  
  ld <- df %>%
    plink_extract_ld_possibly(bfile = bfile, plink_bin = plink_bin, snp_col = {{snp_col}}, effect_allele_col = {{effect_allele_col}})
  
  if(is.null(ld)) {
    return(sumstat %>% mutate(ld_error = TRUE))
  }
  
  # if(!is.null(ld$error)) {
  #   sumstat <- sumstat %>%
  #     mutate(ld = ld$error)
  #   return(sumstat)
  # }
  
  cli::cli_alert_info("Running CARMA")
  z.list<-list()
  ld.list<-list()
  lambda.list<-list()
  z.list[[1]] <- sumstat %>% pull({{z_col}})
  ld.list[[1]] <- as.matrix(ld)
  lambda.list[[1]] <- 1
  CARMA.results <- CARMA::CARMA(z.list, ld.list, lambda.list=lambda.list, outlier.switch = TRUE)
  
  sumstat.result <- sumstat %>% mutate(PIP = CARMA.results[[1]]$PIPs, CS = 0)
  if(length(CARMA.results[[1]]$`Credible set`[[2]])!=0){
    for(l in 1:length(CARMA.results[[1]]$`Credible set`[[2]])){
    sumstat.result$CS[CARMA.results[[1]]$`Credible set`[[2]][[l]]]=l
    }
  }
  
  return(sumstat.result)
}
```
  
```{r example-run_carma}
#' \dontrun{
#' run_carma(locus_df, snp_col = SNP, z_col = z, effect_allele_col = allele1)
#' }
```
  
```{r tests-run_carma}
test_that("run_carma works", {
  expect_true(inherits(run_carma, "function")) 
})
```
  

---    
  
# Gene-based Testing

GWAS summary statistics can be used to perform gene-based testing for associations with the trait/phenotype of interest, rather than SNP/variant-level associations found in GWAS.

## MAGMA

This function provides a wrapper to MAGMA, which performs gene-based testing from GWAS summary statistics. Details of MAGMA described in de Leeuw et al. (PLoS Cumputational Biology 2015; <https://doi.org/10.1371/journal.pcbi.1004219>). The MAGMA binary and reference files are available from the Complex Trait Genetics lab (<https://ctg.cncr.nl/software/magma>).
    
```{r function-magmar}
#' Run MAGMA gene-based analysis
#' 
#' This function provides a wrapper to MAGMA, which performs gene-based testing from GWAS summary statistics. Details of MAGMA described in de Leeuw et al. (PLoS Cumputational Biology 2015; <https://doi.org/10.1371/journal.pcbi.1004219>). The MAGMA binary and reference files are available from the Complex Trait Genetics lab (<https://ctg.cncr.nl/software/magma>).
#' 
#' @param sumstats_df Dataframe containing GWAS summary statistics
#' @param pval_col Column containing p-values
#' @param snp_col Column containing rsids
#' @param samplesize_col Column containing sample size
#' @param magma_bin Path to MAGMA binary
#' @param bfile Path to reference data in plink `bfile` format (path should not include the extensions)
#' @param gene_file Path to file containing gene locations
#' @param out_file Output directory + file prefix
#'
#' @return Path to MAGMA results file
#' @concept genomics
#' @family Gene-based testing
#' @export
#' 
magmar <- function(sumstats_df, pval_col = p_value, snp_col = rsid, samplesize_col = samplesize, magma_bin, bfile, gene_file, out_file) {
  cli::cli_progress_step("Writing summary statistics to temporary file")
  sumstats_file <- fs::file_temp()
  sumstats_df %>%
    select(SNP = {{ snp_col }}, P = {{ pval_col }}, N = {{ samplesize_col }}) %>%
    vroom::vroom_write(sumstats_file)


  cli::cli_progress_step("Running MAGMA")

  # create output path if it doesn't exist
  fs::dir_create(fs::path_dir(out_file))

  processx::run(magma_bin,
    args = c(
      "--bfile", bfile,
      "--gene-annot", gene_file,
      "--pval", sumstats_file, "ncol=N",
      "--gene-model", "snp-wise=mean",
      "--out", out_file
    ),
    error_on_status = FALSE,
    echo_cmd = TRUE,
    echo = TRUE
  )

  genes_out <- paste0(out_file, ".genes.out")
  genes_raw <- paste0(out_file, ".genes.raw")

  return(
    c("genes_out" = genes_out)
  )
}
```
  
```{r example-magmar}
#' \dontrun{
#' magmar(sumstats_df, magma_bin = "/path/to/magma", bfile = "/path/to/bfiles", gene_file = "/path/to/genes", out_file = "magma_output")
#' }
```
  
```{r tests-magmar}
test_that("magmar works", {
  expect_true(inherits(magmar, "function")) 
})
```
    

## S-PrediXcan
    
```{r function-s_predixcan}
#' Run a TWAS using S-PrediXcan
#' 
#' This function is a wrapper around S-PrediXcan, a method of integrating GWAS summary statistics with gene-expression/splicing data to identify genes associated with a trait. The PrediXcan/MetaXcan method is described in Barbeira et al. (Nature Communications 2018; <https://doi.org/10.1038/s41467-018-03621-1>). The MetaXcan tools can be found on Github (<https://github.com/hakyimlab/MetaXcan>) and PredictDB (<https://predictdb.org/>). If S-PrediXcan is run across multiple tissues, the results can be integrated using [levinmisc::s_multixcan()].

#' @param df Dataframe containing GWAS summary statistics
#' @param snp Column containing rsid
#' @param effect_allele Column containing effect allele
#' @param other_allele Column containing non-effect allele
#' @param beta Column containing effect size
#' @param eaf Column containing effect allele frequency
#' @param chr Column containing chromosome
#' @param pos Column containing position
#' @param se Column containing standard error of the effect estimate
#' @param pval Column containing p-value
#' @param samplesize Column containing samplesize
#' @param data Path to MetaXcan data (eg. `"MetaXcan/data"`)
#' @param metaxcan Path to MetaXcan (eg. `"MetaXcan/software"`) 
#' @param output Output directory to save S-PrediXcan results
#' @param model_db_path Path to PrediXcan model database
#' @param model_covariance_path Path to PrediXcan model covariance
#' @param trait_name Name of GWAS trait (used to name output files)
#'
#' @return A dataframe containing the S-PrediXcan results
#' @family TWAS
#' @family Gene-based testing
#' @concept genomics
#' @import dplyr
#' @export

s_predixcan <- function(df, snp = SNP, effect_allele = effect_allele, other_allele = other_allele, beta = beta, eaf = eaf, chr = chr, pos = pos, se = se, pval = pval, samplesize = samplesize, data, metaxcan, output, model_db_path, model_covariance_path, trait_name) {
  fs::dir_create(output, recurse = TRUE)

  shell <- ifelse(Sys.info()["sysname"] == "Windows", "cmd", "sh")
  # write temporary summary statistics file for harmonization
  .fn <- tempfile()
  df %>%
    select(rsid = {{ snp }}, noneffect_allele = {{ other_allele }}, effect_allele = {{ effect_allele }}, effect = {{ beta }}, p_value = {{ pval }}) %>%
    vroom::vroom_write(.fn)
  
  .eqtl_name <- fs::path_file(model_db_path) %>% str_replace("\\.db$", "")
  .harmonize <- paste0(
    "export DATA=", shQuote(data, type = shell),
    # "; export GWAS_TOOLS=", shQuote(gwas_tools, type = shell),
    "; export METAXCAN=", shQuote(metaxcan, type = shell),
    # "; export OUTPUT=", fn,
    "; python3 $METAXCAN/M03_betas.py",
    " --snp_map_file $DATA/coordinate_map/map_snp150_hg19.txt.gz",
    " --gwas_file ", shQuote(.fn, type = shell),
    " --snp_column rsid ",
    " --non_effect_allele_column noneffect_allele ",
    " --effect_allele_column effect_allele ",
    " --beta_column effect ",
    " --pvalue_column p_value ",
    " --keep_non_rsid ",
    " --throw ",
    " --output ", .fn, "_harmonized.txt",
    "; python3 $METAXCAN/SPrediXcan.py",
    " --gwas_file ", .fn, "_harmonized.txt",
    " --snp_column snp",
    " --effect_allele_column effect_allele",
    " --non_effect_allele_column non_effect_allele",
    " --zscore_column zscore",
    " --model_db_path ", shQuote(model_db_path, type = shell),
    " --covariance ", shQuote(model_covariance_path, type = shell),
    " --keep_non_rsid",
    " --additional_output",
    " --model_db_snp_key varID",
    " --throw",
    " --output_file ", fs::path(output, paste0(trait_name, "_", .eqtl_name, "_S-prediXcan.csv"))
  )
  withr::with_envvar(
    new = c(
      "DATA" = data,
      # "GWAS_TOOLS" = gwas_tools,
      "METAXCAN" = metaxcan,
      "OUTPUT" = .fn
    ),
    system(.harmonize)
  )
  on.exit(system(paste0("rm ", .fn, "*")))
  # system(.harmonize)

  vroom::vroom(fs::path(output, paste0(trait_name, "_", .eqtl_name, "_S-prediXcan.csv"))) %>%
    mutate(tissue = .eqtl_name) %>%
    data.table::fwrite(fs::path(output, paste0(trait_name, "_", .eqtl_name, "_S-prediXcan.csv")))

  return(fs::path(output, paste0(trait_name, "_", .eqtl_name, "_S-prediXcan.csv")))
}
```
  
```{r example-s_predixcan}
#' \dontrun{
#' s_predixcan(df, data = "MetaXcan/data", metaxcan = "MetaXcan/software", output = "/path/to/output", model_db_path = "MetaXcan/data/models/eqtl/mashr/mashr_Liver.db", model_covariance_path = "MetaXcan/data/models/eqtl/mashr/mashr_Liver.txt.gz", trait_name = "GWAS_trait")
#' }
```
  
```{r tests-s_predixcan}
test_that("s_predixcan works", {
  expect_true(inherits(s_predixcan, "function")) 
})
```
      

## S-MultiXcan
    
```{r function-s_multixcan}
#' Integrate PrediXcan data across tissues
#' 
#' This function is a wrapper around S-MultiXcan, a tool for identifying genes associate with a trait using GWAS summary statistics. This approach leverages the sharing of eQTLs acorss tissues to improve upon tissue-specific TWAS-methods like S-PrediXcan. This method uses data generated by [levinmisc::s_predixcan()]. The S-MultiXcan method was described in Barbeira et al. (PLOS Genetics 2019; <https://doi.org/10.1371/journal.pgen.1007889>). The MetaXcan tools can be found on Github (<https://github.com/hakyimlab/MetaXcan>) and PredictDB (<https://predictdb.org/>). 

#' @param df Dataframe containing GWAS summary statistics
#' @param snp Column containing rsids
#' @param effect_allele Column containing effect alleles
#' @param other_allele Column containing non-effect alleles
#' @param beta Column containing effect estimates
#' @param eaf Column containing effect allele frequencies
#' @param chr Column containing chromosomes
#' @param pos Column containing positions
#' @param se Column containing standard errors
#' @param pval Column containing p-values
#' @param samplesize Column containing samplesize
#' @param regularization MetaXcan regularization (default = 0.01)
#' @param cutoff_condition_number Numer of eigen values to use when truncating SVD components (default = 30)
#' @param cutoff_eigen_ratio Ratio of eigenvalues to the max eigenvalue, as threshold to use when truncating SVD components. (default = 0.001)
#' @param cutoff_threshold Threshold of variance eigenvalues when truncating SVD (default = 0.4)
#' @param cutoff_trace_ratio Ratio of eigenvalues to trace, to use when truncating SVD (default = 0.01)
#' @param metaxcan_folder Path to folder containing S-PrediXcan result files
#' @param metaxcan_filter Regular expression to filter results files
#' @param metaxcan_file_name_parse_pattern Regular expression to get phenotype name and model name from MetaXcan result files. Assumes that a first group will be matched to phenotype name, and the second to model name.
#' @param models_folder Path to folder containing MetaXcan models (eg. `"MetaXcan/data/models/eqtl/mashr/"`)
#' @param models_name_filter Filter used to identify model files (default = `".*\\.db"`)
#' @param models_name_pattern Filter used to extract trait name from the model (default = `"mashr_(.*)\\.db"`)
#' @param snp_covariance Path to file containing S-MultiXcan covariance (eg. `"MetaXcan/data/models/gtex_v8_expression_mashr_snp_smultixcan_covariance.txt.gz"`)
#' @param data Path to MetaXcan data (eg. `"MetaXcan/data"`)
#' @param metaxcan Path to MetaXcan (eg. `"MetaXcan/software"`) 
#'
#' @return A dataframe containing S-MultiXcan results
#' @import dplyr
#' @export
#' @family TWAS
#' @family Gene-based testing
#' @concept genomics

s_multixcan <- function(df, models_folder, models_name_filter = ".*db", models_name_pattern, snp = SNP, effect_allele = effect_allele, other_allele = other_allele, beta = beta, eaf = eaf, chr = chr, pos = pos, se = se, pval = pval, samplesize = samplesize, regularization = 0.01, cutoff_condition_number = 30, cutoff_eigen_ratio = 0.001, cutoff_threshold = 0.4, cutoff_trace_ratio = 0.01, metaxcan_folder, metaxcan_filter, metaxcan_file_name_parse_pattern, snp_covariance, metaxcan, data) {
  cli::cli_alert_info("Formatting summary statistics")

  gwas_file <- fs::file_temp()
  df %>%
    select(rsid = {{ snp }}, noneffect_allele = {{ other_allele }}, effect_allele = {{ effect_allele }}, effect = {{ beta }}, p_value = {{ pval }}) %>%
    tidyr::drop_na() %>%
    vroom::vroom_write(gwas_file)

  harmonized_gwas <- fs::file_temp()
  processx::run("python3",
    args = c(
      fs::path(metaxcan, "M03_betas.py"),
      "--snp_map_file", fs::path(data, "coordinate_map/map_snp150_hg19.txt.gz"),
      "--gwas_file", gwas_file,
      "--snp_column", "rsid",
      "--non_effect_allele_column", "noneffect_allele",
      "--effect_allele_column", "effect_allele",
      "--beta_column", "effect",
      "--pvalue_column", "p_value",
      "--keep_non_rsid",
      "--throw",
      "--output", harmonized_gwas
    ),
    error_on_status = FALSE,
    echo_cmd = TRUE,
    echo = TRUE
  )

  cli::cli_alert_info("Running S-metaXcan")
  multixcan_output <- fs::file_temp()
  processx::run("python3",
    args = c(
      fs::path(metaxcan, "SMulTiXcan.py"),
      "--models_folder", models_folder,
      "--models_name_filter", models_name_filter,
      "--models_name_pattern", models_name_pattern,
      "--snp_covariance", snp_covariance,
      "--metaxcan_folder", metaxcan_folder,
      "--metaxcan_filter", metaxcan_filter,
      "--metaxcan_file_name_parse_pattern", metaxcan_file_name_parse_pattern,
      "--gwas_file", harmonized_gwas,
      "--snp_column", "snp",
      "--effect_allele_column", "effect_allele",
      "--non_effect_allele_column", "non_effect_allele",
      "--keep_non_rsid",
      # "--beta_column", "effect",
      # "--pvalue_column", "p_value",
      # "--snp_map_file", fs::path(data, "coordinate_map/map_snp150_hg19.txt.gz"),
      "--zscore_column", "zscore",
      "--model_db_snp_key", "varID",
      "--cutoff_condition_number", cutoff_condition_number,
      # "--cutoff_threshold", cutoff_threshold,
      # "--cutoff_trace_ratio", cutoff_trace_ratio,
      # "--regularization", regularization,
      "--throw",
      "--verbosity", "7",
      # "--trimmed_ensemble_id",
      # "--MAX_M", "100",
      "--output", multixcan_output
    ),
    error_on_status = FALSE,
    echo_cmd = TRUE,
    echo = TRUE
  )

  cli::cli_alert_info("Reading results")
  multixcan_res <- data.table::fread(multixcan_output)

  return(multixcan_res)
}
```
  
```{r example-s_multixcan}
#' \dontrun{
#' s_multixcan(df, 
#'  models_folder = "MetaXcan/data/models/eqtl/mashr/",
#'  models_name_filter = ".*\\.db",
#'  models_name_pattern = "mashr_(.*)\\.db",
#'  metaxcan_folder = "/path/to/metaxcan_files/,
#'  metaxcan_filter = "GWAS-trait_mashr_(.*)_S-prediXcan.csv",
#'  metaxcan_file_name_parse_pattern = "(.*)_mashr_(.*)_S-prediXcan.csv",
#'  data = "MetaXcan/data",
#'  metaxcan = "MetaXcan/software",
#'  snp_covariance = "MetaXcan/data/models/gtex_v8_expression_mashr_snp_smultixcan_covariance.txt.gz")
#' }
```
  
```{r tests-s_multixcan}
test_that("s_multixcan works", {
  expect_true(inherits(s_multixcan, "function")) 
})
```
  

---
# Heritability

## LDAK
    
```{r function-ldak_h2}
#' Calculate heritability using LDAK
#' 
#' This function wraps LDAK, a command-line tool for estimating heritability. The tool and associated reference files can be download from the LDAK website (<https://ldak.org/>). The method is described in Zhang et al. (Nature Communications 2021; <https://doi.org/10.1038/s41467-021-24485-y).
#' 
#' @param sumstats_file Path to "munged" GWAS summary statistics file in LDSC format. The current implementation of this function requires rsids to link to other LDAK files. 
#' @param ldak_bin Path to LDAK binary
#' @param ldak_tagfile Path to LDAK tagfile
#' @param sample_prev Sample prevalence of cases (for case-control studies), `NULL` (default) for quantitative traits
#' @param population_prev Population prevalence of cases in the sample (for case-control studies), `NULL` (default) for quantitative traits
#' @param hm3_file Path to hm3 file containing 
#' @param ldak_cutoff Minor allele frequency cutoff (default = 0.01)
#'
#' @return List of dataframes containing LDAK results
#' @concept genomics
#' @family {heritability}
#' @import stringr
#' @export

ldak_h2 <- function(sumstats_file, ldak_bin, ldak_tagfile, sample_prev = NULL, population_prev = NULL, hm3_file, ldak_cutoff = 0.01) {
  # format paths
  cli::cli_progress_step("Formatting paths")
  ldak_bin <- fs::path_abs(ldak_bin)
  ldak_tagfile <- fs::path_abs(ldak_tagfile)
  ldak_in <- fs::file_temp()
  ldak_dir <- fs::path_temp()
  
  # Category annotations
  ldak_annotations <- glue::glue("1 Coding_UCSC*
2 Coding_UCSC.extend.500
3 Conserved_LindbladToh*
4 Conserved_LindbladToh.extend.500
5 CTCF_Hoffman*
6 CTCF_Hoffman.extend.500
7 DGF_ENCODE*
8 DGF_ENCODE.extend.500
9 DHS_peaks_Trynka
10 DHS_Trynka*
11 DHS_Trynka.extend.500
12 Enhancer_Andersson*
13 Enhancer_Andersson.extend.500
14 Enhancer_Hoffman*
15 Enhancer_Hoffman.extend.500
16 FetalDHS_Trynka*
17 FetalDHS_Trynka.extend.500
18 H3K27ac_Hnisz*
19 H3K27ac_Hnisz.extend.500
20 H3K27ac_PGC2*
21 H3K27ac_PGC2.extend.500
22 H3K4me1_peaks_Trynka
23 H3K4me1_Trynka*
24 H3K4me1_Trynka.extend.500
25 H3K4me3_peaks_Trynka
26 H3K4me3_Trynka*
27 H3K4me3_Trynka.extend.500
28 H3K9ac_peaks_Trynka
29 H3K9ac_Trynka*
30 H3K9ac_Trynka.extend.500
31 Intron_UCSC*
32 Intron_UCSC.extend.500
33 PromoterFlanking_Hoffman*
34 PromoterFlanking_Hoffman.extend.500
35 Promoter_UCSC*
36 Promoter_UCSC.extend.500
37 Repressed_Hoffman*
38 Repressed_Hoffman.extend.500
39 SuperEnhancer_Hnisz*
40 SuperEnhancer_Hnisz.extend.500
41 TFBS_ENCODE*
42 TFBS_ENCODE.extend.500
43 Transcr_Hoffman*
44 Transcr_Hoffman.extend.500
45 TSS_Hoffman*
46 TSS_Hoffman.extend.500
47 UTR_3_UCSC*
48 UTR_3_UCSC.extend.500
49 UTR_5_UCSC*
50 UTR_5_UCSC.extend.500
51 WeakEnhancer_Hoffman*
52 WeakEnhancer_Hoffman.extend.500
53 Super_Enhancer_Vahedi*
54 Super_Enhancer_Vahedi.extend.500
55 Typical_Enhancer_Vahedi*
56 Typical_Enhancer_Vahedi.extend.500
57 GERP.NS
58 GERP.RSsup4
59 MAF_Adj_Predicted_Allele_Age
60 MAF_Adj_LLD_AFR
61 Recomb_Rate_10kb
62 Nucleotide_Diversity_10kb
63 Backgrd_Selection_Stat
64 CpG_Content_50kb
65 LDAK_Weightings
66 Base_Category") %>%
  read_delim(col_names = c("category", "annotation"), delim = " ") %>%
  mutate(binary = str_detect(annotation, "\\*")) %>%
  mutate(annotation = str_replace(annotation, "\\*", ""))

  # read files
  cli::cli_progress_step("Reading files")
  hm3_df <- vroom::vroom(hm3_file, col_names = c("SNP", "Predictor"), col_select = c(1:2), col_types = "cc")
  sumstats_df <- vroom::vroom(sumstats_file, show_col_types = FALSE)
  phenotype <- fs::path_file(sumstats_file)


  # write summary statistics
  cli::cli_progress_step("Writing summary statistics")
  sumstats_df %>%
    inner_join(hm3_df, by = c("SNP" = "SNP")) %>%
    select(Predictor, A1, A2, n = N, Z) %>%
    filter(is.finite(Z)) %>%
    vroom::vroom_write(ldak_in)

  cli::cli_progress_step("Running LDAK")
  processx::run(ldak_bin,
    args = c(
      "--sum-hers", phenotype,
      "--summary", ldak_in,
      "--tagfile", ldak_tagfile,
      "--check-sums", "NO",
      if(!is.null(population_prev)){c("--prevalence", population_prev)},
      if(!is.null(sample_prev)){c("--ascertainment", sample_prev)},
      "--cutoff", ldak_cutoff
    ),
    error_on_status = FALSE,
    echo_cmd = TRUE,
    echo = TRUE,
    wd = ldak_dir
  )

  h2_res <- vroom::vroom(fs::dir_ls(ldak_dir, glob = "*.hers*"), show_col_types = FALSE, col_names = c("component", "h2", "h2_sd", "influence", "influence_sd"), skip = 1) %>%
    mutate(category = str_match(component, "\\d+")) %>%
    readr::type_convert() %>%
    left_join(ldak_annotations)
  cat_res <- vroom::vroom(fs::dir_ls(ldak_dir, glob = "*.cats*"), col_names = c("component", "heritability", "sd"), show_col_types = FALSE, skip = 1) %>%
    mutate(category = str_match(component, "\\d+")) %>%
    readr::type_convert() %>%
    left_join(ldak_annotations)
  share_res <- vroom::vroom(fs::dir_ls(ldak_dir, glob = "*.share*"), col_names = c("component", "share", "sd"), show_col_types = FALSE, skip = 1) %>%
    mutate(category = str_match(component, "\\d+")) %>%
    readr::type_convert() %>%
    left_join(ldak_annotations)
  enrich_res <- vroom::vroom(fs::dir_ls(ldak_dir, glob = "*.enrich*"), col_names = c("component", "share", "share_sd", "expected", "enrichment", "enrichment_sd"), show_col_types = FALSE, skip = 1) %>%
    mutate(category = str_match(component, "\\d+")) %>%
    readr::type_convert() %>%
    left_join(ldak_annotations)
  # extra_res <- vroom::vroom(fs::dir_ls(ldak_dir, glob = "*.extra*"), show_col_types = FALSE, skip = 1)

  return(list(
    h2 = h2_res,
    cat = cat_res,
    share = share_res,
    enrich = enrich_res
  ))
}
```
  
```{r example-ldak_h2}
#' \dontrun{
#' ldak_h2(sumstats_file = "/path/to/munged_sumstats", ldak_bin = "/path/to/ldak", ldak_tagfile = "/path/to/tagfile",  hm3_file = "/path/to/hm3")
#' }
```
  
```{r tests-ldak_h2}
test_that("ldak_h2 works", {
  expect_true(inherits(ldak_h2, "function")) 
})
```
  

```{r development-inflate, eval=FALSE}
# Run but keep eval=FALSE to avoid infinite loop
# Execute in the console directly

fusen::inflate(flat_file = "dev/flat_genomics_functions.Rmd", vignette_name = "Genomics Functions")
```

